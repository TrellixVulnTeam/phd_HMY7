{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nengo\n",
    "import nengo.utils.numpy as npext\n",
    "# import nengo_ocl\n",
    "import nengo_gui.ipython\n",
    "\n",
    "import phd\n",
    "\n",
    "# Some plotting niceties\n",
    "plt.rc('figure', figsize=(8, 5))\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "def find_nearest_idx(array, val):\n",
    "    return (np.abs(array-val)).argmin()\n",
    "\n",
    "def ph_labels(phonemes, data, time, every=0.05, thresh=0.5):\n",
    "    for t in np.arange(every, time[-1], every):\n",
    "        t_idx = find_nearest_idx(time, t)\n",
    "        if data[t_idx].max() > thresh:\n",
    "            ph = data[t_idx].argmax()\n",
    "            plt.text(t, 0.9, phonemes[ph],\n",
    "                     horizontalalignment='center',\n",
    "                     verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "if($(IPython.toolbar.selector.concat(' > #kill-run-first')).length == 0){\n",
    "  IPython.toolbar.add_buttons_group([\n",
    "    {\n",
    "      'label'   : 'kill and run-first',\n",
    "      'icon'    : 'fa fa-angle-double-down',\n",
    "      'callback': function(){\n",
    "        IPython.notebook.kernel.restart();\n",
    "        $(IPython.events).one('kernel_ready.Kernel', function(){\n",
    "          var idx = IPython.notebook.get_selected_index();\n",
    "          IPython.notebook.select(0);\n",
    "          IPython.notebook.execute_cell();\n",
    "          IPython.notebook.select(idx);\n",
    "        });\n",
    "      }\n",
    "    }\n",
    "  ], 'kill-run-first');\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 25000.\n",
    "dt = 1. / fs\n",
    "\n",
    "def plot_sound(process, t, dt):\n",
    "    plt.figure()\n",
    "    plt.plot(process.trange(t, dt=dt), process.run(t, dt=dt))\n",
    "    plt.xlim(right=t)\n",
    "    sns.despine()\n",
    "\n",
    "plot_sound(phd.processes.WavFile('speech.wav'), 0.667, dt)\n",
    "# plot_sound(phd.processes.WhiteNoise(), 0.1, dt)\n",
    "# plot_sound(phd.processes.Tone(250), 0.1, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditory periphery\n",
    "\n",
    "Making heavy use of [Brian hears](http://www.briansimulator.org/docs/hears.html),\n",
    "but should also investigate other periphery models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = phd.Sermo(execution=False)\n",
    "periphery = model.recognition.periphery\n",
    "periphery.fs = 20000\n",
    "periphery.freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "periphery.sound_process = phd.processes.WhiteNoise()\n",
    "periphery.auditory_filter = phd.filters.gammatone(periphery.freqs)\n",
    "net = model.build()\n",
    "\n",
    "with net:\n",
    "    ihc_p = nengo.Probe(net.periphery.ihc, synapse=None)\n",
    "    an_in_p = nengo.Probe(net.periphery.an.input, synapse=None)\n",
    "    an_p = nengo.Probe(net.periphery.an.add_neuron_output(), synapse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nengo.utils.matplotlib import rasterplot\n",
    "\n",
    "dt = 1. / periphery.freqs.max()\n",
    "print(\"dt=%.5f\" % dt)\n",
    "sim = nengo.Simulator(net, dt=dt)\n",
    "sim.run(0.1)\n",
    "\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[ihc_p], sim.trange(), periphery.freqs)\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[an_in_p], sim.trange(), periphery.freqs)\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[an_p])\n",
    "plt.ylim(0, net.periphery.an.n_neurons * net.periphery.an.n_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in net.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = phd.Sermo(execution=False)\n",
    "periphery = model.recognition.periphery\n",
    "periphery.fs = 20000\n",
    "periphery.freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "periphery.sound_process = phd.processes.WavFile('speech.wav')\n",
    "periphery.auditory_filter = phd.filters.gammatone(periphery.freqs)\n",
    "fast_deriv = model.recognition.add_derivative('TrippFF', delay=0.01)\n",
    "slow_deriv = model.recognition.add_derivative('TrippFF', delay=0.1)\n",
    "net = model.build()\n",
    "\n",
    "with net:\n",
    "    ihc_p = nengo.Probe(net.periphery.ihc, synapse=None, sample_every=0.001)\n",
    "    an_p = nengo.Probe(net.periphery.an.output, synapse=0.01, sample_every=0.001)\n",
    "    fd_p = nengo.Probe(net.derivatives[0.01].output, synapse=0.01, sample_every=0.001)\n",
    "    sd_p = nengo.Probe(net.derivatives[0.1].output, synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / net.periphery.freqs.max()\n",
    "sim = nengo.Simulator(net, dt=dt)\n",
    "sim.run(0.667)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "phd.plots.cochleogram(sim.data[ihc_p], sim.trange(0.001), net.periphery.freqs)\n",
    "plt.subplot(2, 2, 2)\n",
    "phd.plots.cochleogram(sim.data[an_p], sim.trange(0.001), net.periphery.freqs)\n",
    "plt.subplot(2, 2, 3)\n",
    "phd.plots.cochleogram(sim.data[fd_p], sim.trange(0.001), net.periphery.freqs)\n",
    "plt.subplot(2, 2, 4)\n",
    "phd.plots.cochleogram(sim.data[sd_p], sim.trange(0.001), net.periphery.freqs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in net.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = phd.Sermo(execution=False)\n",
    "periphery = model.recognition.periphery\n",
    "periphery.fs = 20000\n",
    "periphery.freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "periphery.sound_process = phd.processes.WavFile('speech.wav')\n",
    "periphery.auditory_filter = phd.filters.gammatone(periphery.freqs)\n",
    "fast_deriv = model.recognition.add_derivative('TrippFF', delay=0.01)\n",
    "slow_deriv = model.recognition.add_derivative('TrippFF', delay=0.1)\n",
    "vow_detector = model.recognition.add_phoneme_detector(\n",
    "    name='vowel', derivatives=[0.01, 0.1], phonemes=phd.timit.vowels)\n",
    "cons_detector = model.recognition.add_phoneme_detector(\n",
    "    name='consonant', derivatives=[0.01, 0.01], phonemes=phd.timit.consonants)\n",
    "phd.timit.TrainingData(model, vow_detector).generate()\n",
    "phd.timit.TrainingData(model, cons_detector).generate()\n",
    "\n",
    "net = model.build()\n",
    "with net:\n",
    "    vowel_p = nengo.Probe(net.detectors['vowel'].output,synapse=0.01, sample_every=0.001)\n",
    "    cons_p = nengo.Probe(net.detectors['consonant'].output, synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print phd.timit.TrainingData(model, vow_detector).cache_file()\n",
    "print phd.timit.TrainingData(model, cons_detector).cache_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / net.periphery.freqs.max()\n",
    "sim = nengo.Simulator(net, dt=dt)\n",
    "sim.run(0.667)\n",
    "t = sim.trange(0.001)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, sim.data[vowel_p])\n",
    "plt.xlim(right=t[-1])\n",
    "ph_labels(sorted(phd.timit.vowels), sim.data[vowel_p], sim.trange(0.001))\n",
    "sns.despine()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, sim.data[cons_p])\n",
    "plt.xlim(right=t[-1])\n",
    "ph_labels(sorted(phd.timit.consonants), sim.data[cons_p], sim.trange(0.001))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in net.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SumPool hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = phd.Sermo(execution=False)\n",
    "periphery = model.recognition.periphery\n",
    "periphery.fs = 20000\n",
    "periphery.freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "periphery.sound_process = phd.processes.WavFile('speech.wav')\n",
    "periphery.auditory_filter = phd.filters.gammatone(periphery.freqs)\n",
    "fast_deriv = model.recognition.add_derivative('TrippFF', delay=0.01)\n",
    "slow_deriv = model.recognition.add_derivative('TrippFF', delay=0.1)\n",
    "vow_detector = model.recognition.add_phoneme_detector(\n",
    "    name='vowel', hierarchical='SumPool', pooling=4, derivatives=[0.1], phonemes=phd.timit.vowels)\n",
    "cons_detector = model.recognition.add_phoneme_detector(\n",
    "    name='consonant', hierarchical='SumPool', pooling=4, derivatives=[0.01], phonemes=phd.timit.consonants)\n",
    "phd.timit.TrainingData(model, vow_detector).generate()\n",
    "phd.timit.TrainingData(model, cons_detector).generate()\n",
    "\n",
    "net = model.build()\n",
    "with net:\n",
    "    vowel_p = nengo.Probe(net.detectors['vowel'].output,synapse=0.01, sample_every=0.001)\n",
    "    cons_p = nengo.Probe(net.detectors['consonant'].output, synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print phd.timit.TrainingData(model, vow_detector).cache_file()\n",
    "print phd.timit.TrainingData(model, cons_detector).cache_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / net.periphery.freqs.max()\n",
    "sim = nengo.Simulator(net, dt=dt)\n",
    "sim.run(0.667)\n",
    "t = sim.trange(0.001)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, sim.data[vowel_p])\n",
    "plt.xlim(right=t[-1])\n",
    "ph_labels(sorted(phd.timit.vowels), sim.data[vowel_p], sim.trange(0.001))\n",
    "sns.despine()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, sim.data[cons_p])\n",
    "plt.xlim(right=t[-1])\n",
    "ph_labels(sorted(phd.timit.consonants), sim.data[cons_p], sim.trange(0.001))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in net.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ProdTile hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = phd.Sermo(execution=False)\n",
    "periphery = model.recognition.periphery\n",
    "periphery.fs = 20000\n",
    "periphery.freqs = phd.filters.erbspace(20, 10000, 48)\n",
    "periphery.sound_process = phd.processes.WavFile('speech.wav')\n",
    "periphery.auditory_filter = phd.filters.gammatone(periphery.freqs)\n",
    "fast_deriv = model.recognition.add_derivative('TrippFF', delay=0.01)\n",
    "slow_deriv = model.recognition.add_derivative('TrippFF', delay=0.1)\n",
    "vow_detector = model.recognition.add_phoneme_detector(\n",
    "    name='vowel', hierarchical='ProdTile', spread=1, center=0,\n",
    "    derivatives=[0.1], phonemes=phd.timit.vowels)\n",
    "cons_detector = model.recognition.add_phoneme_detector(\n",
    "    name='consonant', hierarchical='ProdTile', spread=1,\n",
    "    center=0, derivatives=[0.01], phonemes=phd.timit.consonants)\n",
    "phd.timit.TrainingData(model, vow_detector).generate()\n",
    "phd.timit.TrainingData(model, cons_detector).generate()\n",
    "\n",
    "net = model.build()\n",
    "with net:\n",
    "    vowel_p = nengo.Probe(net.detectors['vowel'].output,synapse=0.01, sample_every=0.001)\n",
    "    cons_p = nengo.Probe(net.detectors['consonant'].output, synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print phd.timit.TrainingData(model, vow_detector).cache_file()\n",
    "print phd.timit.TrainingData(model, cons_detector).cache_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / net.periphery.freqs.max()\n",
    "sim = nengo.Simulator(net, dt=dt)\n",
    "sim.run(0.667)\n",
    "t = sim.trange(0.001)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, sim.data[vowel_p])\n",
    "plt.xlim(right=t[-1])\n",
    "ph_labels(sorted(phd.timit.vowels), sim.data[vowel_p], sim.trange(0.001))\n",
    "sns.despine()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, sim.data[cons_p])\n",
    "plt.xlim(right=t[-1])\n",
    "ph_labels(sorted(phd.timit.consonants), sim.data[cons_p], sim.trange(0.001))\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
