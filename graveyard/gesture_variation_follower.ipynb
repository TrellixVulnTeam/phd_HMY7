{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory classification with Gesture Variation Follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "t1 = np.sin(5. * np.pi * np.linspace(0, 0.5, 20)) * 0.5 + 0.5\n",
    "t2 = np.sin(2. * np.pi * np.linspace(0, 2, 15)) * 0.5 + 0.5\n",
    "plt.plot(t1 + np.random.normal(scale=0.05, size=t1.size))\n",
    "plt.plot(t2 + np.random.normal(scale=0.05, size=t2.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class GVF(object):\n",
    "    def __init__(self, ns, sigs, icov, resThresh, nu=0.):\n",
    "        \"\"\"Constructor of GVF.\n",
    "\n",
    "        ns          number of particles\n",
    "        sigs        table of sigmas for each adapted parameters\n",
    "        icov        static std dev for observation likelihood\n",
    "        resThresh   threshold for resampling\n",
    "        nu          t-dist parameter\n",
    "        \"\"\"\n",
    "        self.pdim = sigs.shape[0]  # number of state dimensions\n",
    "\n",
    "        self.X = np.zeros((ns, self.pdim))  # Each row is a particle\n",
    "        self.g = np.zeros(ns, dtype=int)  # gesture index for each particle [g is ns x 1]\n",
    "        self.w = np.zeros(ns)  # weight of each particle [w is ns x 1]\n",
    "        self.logW = np.zeros(ns)  # non-normalized weights\n",
    "        self.sigt = np.sqrt(sigs)  # vector of variances\n",
    "        # Filled in in `spreadParticles`\n",
    "        self.means = None  # vector of means for particles initial spreading\n",
    "        self.ranges = None   # vector of ranges around the means for particles initial spreading\n",
    "        self.R_multi = []  # gesture references (several examples)\n",
    "        self.R_single = []  # gesture references (1 example)\n",
    "        self.icov_single = icov  # inverse covariance (coeff. for the diagonal matrix)\n",
    "        self.nu = nu  # degree of freedom for the t-distribution; if 0, use a Gaussian\n",
    "        self.sp, self.sv, self.sr, self.ss = sigs # sigma values (actually, their square root)\n",
    "        self.resampling_threshold = resThresh\n",
    "        self.lrndGstr = -1  # number of learned gestures\n",
    "        self.multivar = False  # whether to be multivariate? deprecated?\n",
    "        self.gestureLengths = []  # length of each reference gesture\n",
    "\n",
    "    def initweights(self):\n",
    "        ns = self.w.size\n",
    "        self.w[...] = 1. / ns\n",
    "\n",
    "    def addTemplate(self):\n",
    "        \"\"\"Add a template to the database by allocating the memory.\n",
    "    \n",
    "        Needs to be called before the fillTemplate() method.\n",
    "        \"\"\"\n",
    "        self.lrndGstr += 1\n",
    "        self.R_single.append([])\n",
    "        self.gestureLengths.append(0)\n",
    "\n",
    "    def fillTemplate(self, id, data):\n",
    "        \"\"\"Fill the template given by the integer 'id'.\n",
    "\n",
    "        With the current data vector 'data'\n",
    "        \"\"\"\n",
    "        if id <= self.lrndGstr:\n",
    "            self.R_single[id].append(data)\n",
    "            self.gestureLengths[id] += 1\n",
    "\n",
    "    def spreadParticles(self, meanPVRS, rangePVRS):\n",
    "        \"\"\"Spread particles by sampling values from given intervals.\n",
    "\n",
    "        The current implemented distribution is uniform.\n",
    "\n",
    "        meanPVRS    mean values around which the particles are sampled\n",
    "        rangePVRS   range values defining how far from the means the particles can be spread\n",
    "        \"\"\"\n",
    "        ns = self.X.shape[0]\n",
    "        ngestures = self.lrndGstr+1\n",
    "\n",
    "        # Keep track of means / ranges\n",
    "        self.means = meanPVRS\n",
    "        self.ranges = rangePVRS\n",
    "\n",
    "        # Spread particles using a uniform distribution\n",
    "        for i in range(self.pdim):\n",
    "            for n in range(ns):\n",
    "                self.X[n, i] = np.random.uniform(-0.5, 0.5) * rangePVRS[i] + meanPVRS[i]\n",
    "\n",
    "        # Weights are also uniformly spread\n",
    "        self.initweights()\n",
    "        self.logW[:] = 0.0\n",
    "\n",
    "        pass\n",
    "\n",
    "    def particleFilter(self, obs):\n",
    "        \"\"\"Core algorithm: does one step of inference using particle filtering\"\"\"\n",
    "        ns = self.X.shape[0]  # n_particles\n",
    "        # Particles outside\n",
    "        particle_before_0 = []\n",
    "        particle_after_1 = []\n",
    "\n",
    "        # Main loop: same process for each particle (row n in X)\n",
    "        for n in range(ns):\n",
    "            # Move the particle\n",
    "            # Position respects a first order dynamic: p = p + v/L\n",
    "            self.X[n, 0] = (self.X[n, 0]\n",
    "                            + np.random.normal(1) * self.sigt[0]\n",
    "                            + self.X[n, 1] / self.gestureLengths[self.g[n]])\n",
    "\n",
    "            # Move the other state elements according to Gaussian noise\n",
    "            for l in range(1, self.pdim):\n",
    "                self.X[n, l] = self.X[n, l] + np.random.normal(1) * self.sigt[0]\n",
    "\n",
    "            x_n = self.X[n]\n",
    "            if x_n[0] < 0:\n",
    "                # Can't observe a particle outside (0, 1) range [this behavior could be changed]\n",
    "                self.w[n] = 0\n",
    "                particle_before_0.append(n)\n",
    "                self.logW[n] = -np.inf\n",
    "            elif x_n[0] > 1:\n",
    "                self.w[n] = 0\n",
    "                particle_after_1.append(n)\n",
    "                self.logW[n] = -np.inf\n",
    "            else:\n",
    "                pgi = self.g[n]  # gesture index\n",
    "                frameindex = min(int(self.gestureLengths[pgi]-1),\n",
    "                                 int(np.floor(x_n[0] * self.gestureLengths[pgi])))\n",
    "                vref = np.array(self.R_single[pgi][frameindex])\n",
    "\n",
    "                # If incoming data is 2-dimensional: we assume it is a drawn shape!\n",
    "                if obs.size == 2:\n",
    "                    # scaling\n",
    "                    vref *= x_n[2]\n",
    "                    # rotation\n",
    "                    alpha = x_n[3]\n",
    "                    rotmat = np.array([np.cos(alpha), -np.sin(alpha), np.sin(alpha), np.cos(alpha)])\n",
    "                    vref = rotmat * vref  # or np.dot?\n",
    "                elif obs.size == 3:\n",
    "                    # scaling\n",
    "                    vref *= x_n[2]\n",
    "\n",
    "                # Observation likelihood and update weights\n",
    "                dist = np.dot(vref - obs, vref - obs) * self.icov_single\n",
    "                if self.nu == 0.:  # Gaussian distribution\n",
    "                    self.w[n] *= np.exp(-dist)\n",
    "                    self.logW[n] += -dist\n",
    "                else:  # Student's distribution\n",
    "                    # NB! dimension is 2\n",
    "                    self.w[n] *= np.power(dist / self.nu + 1, -self.nu / 2 - 1)\n",
    "                    self.logW[n] += (-self.nu / 2 - 1) * np.log(dist / nu + 1)\n",
    "        \n",
    "        # TODO: here we should compute the 'absolute likelihood' as log(w) before normalization\n",
    "        # this absolute likelihood could be used as a raw criterion for segmentation\n",
    "        for n in range(len(particle_before_0)):\n",
    "            # Spread particles using a uniform distribution\n",
    "            for i in range(self.pdim):\n",
    "                self.X[particle_before_0[n], i] = np.random.uniform(-0.5, 0.5) * self.ranges[i] + self.means[i]\n",
    "            self.w[particle_before_0[n]] = 1. / ns\n",
    "            self.g[particle_before_0[n]] = n % (self.lrndGstr + 1)\n",
    "        for n in range(len(particle_after_1)):\n",
    "            # Spread particles using a uniform distribution\n",
    "            for i in range(self.pdim):\n",
    "                self.X[particle_after_1[n], i] = np.random.uniform(-0.5, 0.5) * self.ranges[i] + self.means[i]\n",
    "            self.w[particle_after_1[n]] = 1. / ns\n",
    "            self.g[particle_after_1[n]] = n % (self.lrndGstr + 1)\n",
    "\n",
    "        # Normalization - resampling\n",
    "        self.w /= self.w.sum()\n",
    "        neff = 1. / np.dot(self.w, self.w)\n",
    "        if neff < self.resampling_threshold:\n",
    "            self.resampleAccordingToWeights()\n",
    "            self.initweights()\n",
    "\n",
    "    def resampleAccordingToWeights(self):\n",
    "        ns = self.w.shape[0]\n",
    "        oldX = np.array(self.X)\n",
    "        oldG = np.array(self.g)\n",
    "        oldLogW = np.array(self.logW)\n",
    "        c = np.zeros(ns)\n",
    "\n",
    "        for i in range(1, ns):\n",
    "            c[i] = c[i-1] + self.w[i]\n",
    "\n",
    "        i = 0\n",
    "        u0 = np.random.uniform(0, 1) / ns\n",
    "        for j in range(ns):\n",
    "            uj = u0 + (j + 0.) / ns\n",
    "            while uj > c[i] and i < ns - 1:\n",
    "                i += 1\n",
    "            self.X[j] = oldX[i]\n",
    "            self.g[j] = oldG[i]\n",
    "            self.logW[j] = oldLogW[i]\n",
    "\n",
    "    def infer(self, vect):\n",
    "        \"\"\"Run inference on the input dataset.\n",
    "\n",
    "        Each row is a temporal observation.\n",
    "        For each row the incremental inference procedure is called.\n",
    "\n",
    "        vect     whole data matrix\n",
    "        \"\"\"\n",
    "        self.particleFilter(vect)\n",
    "\n",
    "    def getGestureConditionalProbabilities(self):\n",
    "        \"\"\"Return values of each gesture's likelihood\"\"\"\n",
    "        ngestures = self.lrndGstr+1\n",
    "        ns = self.X.shape[0]\n",
    "        gp = np.zeros(ngestures)\n",
    "        for n in range(ns):\n",
    "            gp[self.g[n]] += self.w[n]\n",
    "        return gp\n",
    "\n",
    "    def getGestureLikelihoods(self):\n",
    "        \"\"\"Return values of each gesture's likelihood\"\"\"\n",
    "        ngestures = self.lrndGstr+1\n",
    "        ns = self.X.shape[0]\n",
    "        numg = np.zeros(ngestures)\n",
    "        gp = np.zeros(ngestures)\n",
    "        for n in range(ns):\n",
    "            if self.logW[n] > -np.inf:\n",
    "                gp[self.g[n]] += self.logW[n]\n",
    "                numg[self.g[n]] += 1\n",
    "        for n in range(ngestures):\n",
    "            if numg[n] == 0:\n",
    "                gp[n] = -np.inf\n",
    "            else:\n",
    "                gp[n] = gp[n] / numg[n]\n",
    "        return gp\n",
    "\n",
    "    def getEndGestureProbabilities(self, minpos=0.):\n",
    "        ngestures = self.lrndGstr+1\n",
    "        ns = self.X.shape[0]\n",
    "        gp = np.zeros(ngestures)\n",
    "        for n in range(ns):\n",
    "            if self.X[n, 0] > minpos:\n",
    "                gp[self.g[n]] += self.w[n]\n",
    "        return gp\n",
    "\n",
    "    def getEstimatedStatus(self):\n",
    "        \"\"\"Return values of estimated features\"\"\"\n",
    "        ngestures = self.lrndGstr+1\n",
    "        ns = self.X.shape[0]\n",
    "        es = np.zeros((ngestures, self.pdim+1))  # PVRSW\n",
    "\n",
    "        for n in range(ns):\n",
    "            gi = self.g[n]\n",
    "            es[gi, :self.pdim] += self.X[n] * self.w[n]\n",
    "            es[gi, self.pdim] += self.w[n]\n",
    "\n",
    "        # Ensure we don't get nans\n",
    "        es[es == 0] = np.finfo(float).eps\n",
    "        for gi in range(ngestures):\n",
    "            es[gi, :self.pdim] /= es[gi, self.pdim]\n",
    "\n",
    "        return es\n",
    "\n",
    "    def getResamplingThreshold(self):\n",
    "        return self.resampling_threshold\n",
    "\n",
    "    def getNbOfParticles(self):\n",
    "        return self.w.size\n",
    "\n",
    "    def getnbOfTemplates(self):\n",
    "        return self.gestureLengths.size\n",
    "\n",
    "    def getLengthOfTemplateByInd(self, ind):\n",
    "        if ind < self.gestureLengths.size:\n",
    "            return self.gestureLengths[ind]\n",
    "        return -1\n",
    "\n",
    "    def getTemplateByInd(self, ind):\n",
    "        if ind < self.gestureLengths.size:\n",
    "            return self.R_single[ind]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def setIcovSingleValue(self, f):\n",
    "        if f > 0:\n",
    "            self.icov_single = f\n",
    "\n",
    "    def setAdaptSpeed(self, speed):\n",
    "        if speed.size == self.pdim:\n",
    "            self.sigt = np.sqrt(speed)\n",
    "\n",
    "    def setResamplingThreshold(self, r):\n",
    "        self.resampling_threshold = r\n",
    "\n",
    "    def clear(self):\n",
    "        del self.R_single[:]\n",
    "        del self.gestureLengths[:]\n",
    "        self.lrndGstr = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so = 0.2  # sigma observation?\n",
    "gvf = GVF(ns=2000,\n",
    "          sigs=np.array([0.0001, 0.01, 0.000001, 0.0001]),\n",
    "          icov=1./(so * so),\n",
    "          resThresh=1000,\n",
    "          nu=0.)\n",
    "mpvrs = np.array([0.05, 1.0, 1.0, 0.0])\n",
    "rpvrs = np.array([0.1, 0.4, 0.3, 0.0])\n",
    "\n",
    "# First, add some templates with 'addTemplate', 'fillTemplate'\n",
    "gvf.addTemplate()\n",
    "gvf.addTemplate()\n",
    "# Give some noisy examples\n",
    "for _ in range(2):\n",
    "    gvf.fillTemplate(0, t1 + np.random.normal(scale=0.05, size=t1.size))\n",
    "    gvf.fillTemplate(1, t2 + np.random.normal(scale=0.05, size=t2.size))\n",
    "\n",
    "# Second, call 'spreadParticles' to start the particle filters\n",
    "gvf.spreadParticles(mpvrs, rpvrs)\n",
    "\n",
    "# Then, you can generate observations and call 'infer'\n",
    "for i, obs in enumerate(t1):\n",
    "    gvf.infer(obs)\n",
    "    if i % 3 == 0:\n",
    "        print(gvf.getEstimatedStatus())\n",
    "        print(gvf.getGestureConditionalProbabilities())\n",
    "        print(gvf.getGestureLikelihoods())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
