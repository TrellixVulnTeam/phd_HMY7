{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5 state Markov chain, S1 to S5\n",
    "# state at time t = qt\n",
    "# P[qt = Si | qt-1=S1...] = P[qt = Si | qt-1 = Si]\n",
    "# state transition probabilities A\n",
    "# a_ij = P[qt = Sj | qt-1 = Si], 1 <= i; j <= N\n",
    "#  a_ij >= 0\n",
    "#  sum(j to N) a_ij = 1\n",
    "\n",
    "# Weather example: S1 = rain (snow), S2 = cloudy, S3 = sunny\n",
    "\n",
    "# transition probs\n",
    "a = np.array([[0.4, 0.3, 0.3], [0.2, 0.6, 0.2], [0.1, 0.1, 0.8]])\n",
    "# Given weather on day 1 (t = 1) is sunny (S3),\n",
    "# probability of sun-sun-rain-rain-sun-cloudy-sun; i.e.,\n",
    "# O = {S3, S3, S3, S1, S1, S3, S2, S3}\n",
    "# P(O|model)\n",
    "o = [2, 2, 2, 0, 0, 2, 1, 2]\n",
    "p = 1\n",
    "for prev_o, curr_o in zip(o[:-1], o[1:]):\n",
    "    p *= a[prev_o, curr_o]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is the prob. it stays in the current state for `d` days?\n",
    "# I.e., O = [Si] * d + [Sj]\n",
    "i = 1\n",
    "d = 10\n",
    "pi_d = a[i, i] ** (d -1) * (1 - a[i, i])\n",
    "# Expected number of days it'll stay the current state\n",
    "expect_di = 1 / (1 - a[i, i])\n",
    "pi_d, expect_di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM definition\n",
    "\n",
    "- $N$: number of states in the model (e.g., # of urns)\n",
    "- $S=S_{1...N}$: the states in the model\n",
    "- $q_t$: the state at time $t$\n",
    "- $M$: the number of observation symbols per state (i.e., alphabet size)\n",
    "- $V=v_{1...M}$: the observation symbols\n",
    "- $A=\\{a_{ij}\\}; a_{ij} = P[q_{t+1} = S_j|q_t = S_i]$: state transition probability distribution\n",
    "- $B=\\{b_j(k)\\}; b_j(k) = P[v_k\\text{ at }t|q_t = S_j]$: observation symbol probability distribution in state $j$\n",
    "- $\\pi=\\{\\pi_i\\}; \\pi_i = P[q_1 = S_i]$: initial state distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wikipedia examples\n",
    "\n",
    "states = ('Healthy', 'Fever')\n",
    " \n",
    "observations = ('normal', 'cold', 'dizzy')\n",
    " \n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    " \n",
    "transition_probability = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.6},\n",
    "   }\n",
    " \n",
    "emission_probability = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "}\n",
    "\n",
    "def fwd_bkw(x, states, a_0, a, e):\n",
    "    L = len(x)\n",
    " \n",
    "    fwd = []\n",
    "    f_prev = {}\n",
    "    # forward part of the algorithm\n",
    "    for i, x_i in enumerate(x):\n",
    "        f_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for the forward part\n",
    "                prev_f_sum = a_0[st]\n",
    "            else:\n",
    "                prev_f_sum = sum(f_prev[k]*a[k][st] for k in states)\n",
    " \n",
    "            f_curr[st] = e[st][x_i] * prev_f_sum\n",
    " \n",
    "        fwd.append(f_curr)\n",
    "        f_prev = f_curr\n",
    "    \n",
    "    end_st = 'Fever'\n",
    "    p_fwd = sum(f_curr[k]*a[k][end_st] for k in states)\n",
    " \n",
    "    bkw = []\n",
    "    b_prev = {}\n",
    "    # backward part of the algorithm\n",
    "    for i, x_i_plus in enumerate(reversed(x[1:]+(None,))):\n",
    "        b_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for backward part\n",
    "                b_curr[st] = a[st][end_st]\n",
    "            else:\n",
    "                b_curr[st] = sum(a[st][l]*e[l][x_i_plus]*b_prev[l] for l in states)\n",
    " \n",
    "        bkw.insert(0,b_curr)\n",
    "        b_prev = b_curr\n",
    " \n",
    "    p_bkw = sum(a_0[l] * e[l][x[0]] * b_curr[l] for l in states)\n",
    " \n",
    "    # merging the two parts\n",
    "    posterior = []\n",
    "    for i in range(L):\n",
    "        posterior.append({st: fwd[i][st]*bkw[i][st]/p_fwd for st in states})\n",
    " \n",
    "    #assert p_fwd == p_bkw\n",
    "    return fwd, bkw, posterior\n",
    "\n",
    "def example():\n",
    "    return fwd_bkw(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability)\n",
    "\n",
    "print \"--- fwd-bkwd-posterior\"\n",
    "for line in example():\n",
    "    print(' '.join(map(str, line)))\n",
    "\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "    \n",
    "    # Initialize base cases (t == 0)\n",
    "    for y in states:\n",
    "        V[0][y] = start_p[y] * emit_p[y][obs[0]]\n",
    "        path[y] = [y]\n",
    "    \n",
    "    # Run Viterbi for t > 0\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    "\n",
    "        for y in states:\n",
    "            (prob, state) = max((V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states)\n",
    "            V[t][y] = prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "\n",
    "        # Don't need to remember the old paths\n",
    "        path = newpath\n",
    "    \n",
    "    # Return the most likely sequence over the given time frame\n",
    "    n = len(obs) - 1\n",
    "    print_dptable(V)\n",
    "    (prob, state) = max((V[n][y], y) for y in states)\n",
    "    return (prob, path[state])\n",
    "\n",
    "def print_dptable(V):\n",
    "    s = \"    \" + \" \".join((\"%7d\" % i) for i in range(len(V))) + \"\\n\"\n",
    "    for y in V[0]:\n",
    "        s += \"%.5s: \" % y\n",
    "        s += \" \".join(\"%.7s\" % (\"%f\" % v[y]) for v in V)\n",
    "        s += \"\\n\"\n",
    "    print(s)\n",
    "\n",
    "print \"--- viterbi\"\n",
    "def example():\n",
    "    return viterbi(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability)\n",
    "print(example())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_pdf(pdf, size=1):\n",
    "    states = np.arange(pdf.size)\n",
    "    dist = stats.rv_discrete(name='pdf', values=(states, pdf))\n",
    "    return dist.rvs(size)\n",
    "\n",
    "def observe(n_t, a, b, pi):\n",
    "    q_t = sample_pdf(pi)  # initial state\n",
    "    os = []\n",
    "    qs = [q_t]\n",
    "    for t in xrange(n_t):\n",
    "        o_t = sample_pdf(b[q_t])\n",
    "        q_t = sample_pdf(a[q_t])\n",
    "        os.append(o_t)\n",
    "        qs.append(q_t)\n",
    "\n",
    "\n",
    "class HMM(object):\n",
    "    def __init__(self, a, b, pi):\n",
    "        assert a.shape[0] == a.shape[1]\n",
    "        assert b.shape[0] == a.shape[0]\n",
    "        assert pi.size == a.shape[0]\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.pi = pi\n",
    "        self.N = self.a.shape[0]\n",
    "        self.M = self.b.shape[1]\n",
    "        self.states = np.arange(self.N, dtype=int)\n",
    "\n",
    "    def observe(self, n_t):\n",
    "        return observe(n_t, self.a, self.b, self.pi)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # forward variable;\n",
    "        # alpha_t(i) = P(past O sequence, qt = Si | hmm)\n",
    "        f_prev = self.b.T[obs[0]] * self.pi\n",
    "        fwd = [[f_prev]]\n",
    "        for o_i in obs[1:]:\n",
    "            f_curr = np.zeros(self.N)\n",
    "            prev_f_sum = np.sum(f_prev * self.a.T, axis=1)\n",
    "            f_curr = self.b.T[o_i] * prev_f_sum\n",
    "            fwd.append([f_curr])\n",
    "            f_prev = f_curr\n",
    "        return np.concatenate(fwd, axis=0)\n",
    "\n",
    "    def backward(self, obs):\n",
    "        # backward variable;\n",
    "        # beta_t(i) = P(future O sequence|qt = Si, hmm)\n",
    "        b_prev = np.ones(self.N)\n",
    "        bkw = [[b_prev]]\n",
    "        for i, o_i_plus in enumerate(reversed(obs[1:])):\n",
    "            b_curr = np.sum(a * self.b.T[o_i_plus] * b_prev, axis=1)\n",
    "            bkw.insert(0, [b_curr])\n",
    "            b_prev = b_curr\n",
    "        return np.concatenate(bkw, axis=0)\n",
    "\n",
    "    def obs_probability(self, obs):\n",
    "        \"\"\"Computed with the forward-backward procedure.\"\"\"\n",
    "        fwd = self.forward(obs)\n",
    "        return np.sum(fwd[-1])\n",
    "\n",
    "    def optimal_path(self, obs):\n",
    "        \"\"\"Computed with Viterbi algorithm.\"\"\"\n",
    "        return self.viterbi(obs)[1]\n",
    "\n",
    "    def viterbi(self, obs):\n",
    "        V = [self.pi * self.b.T[obs[0]]]\n",
    "        path = [[s] for s in self.states]\n",
    "\n",
    "        for t in xrange(1, len(obs)):\n",
    "            v = V[t-1] * (self.a * self.b.T[obs[t]]).T\n",
    "            prob, state = np.amax(v, axis=1), np.argmax(v, axis=1)\n",
    "            V.append(prob)\n",
    "            path = [path[state[y]] + [y] for y in self.states]\n",
    "        # Return the most likely sequence\n",
    "        prob, state = np.amax(V[-1]), np.argmax(V[-1])\n",
    "        return prob, path[state]\n",
    "\n",
    "    def update(self, obs, n_iters=1):\n",
    "        \"\"\"Update a, b, pi so that `obs` is more likely.\n",
    "\n",
    "        Uses the Baum-Welch algorithm.\n",
    "        \"\"\"\n",
    "        obs = np.asarray(obs)\n",
    "        print(\"Before P(obs) = %f\" % self.obs_probability(obs))\n",
    "\n",
    "        for _ in xrange(n_iters):\n",
    "            alpha = self.forward(obs)\n",
    "            beta = self.backward(obs)\n",
    "\n",
    "            xi = np.zeros((self.N, self.N, len(obs) - 1))\n",
    "            for t in xrange(len(obs) - 1):\n",
    "                denom = np.dot(np.dot(alpha[t], self.a) * self.b.T[obs[t+1]],\n",
    "                               beta[t+1])\n",
    "                for i in xrange(self.N):\n",
    "                    numer = (alpha[t, i]\n",
    "                            * self.a[i]\n",
    "                            * self.b.T[obs[t+1]]\n",
    "                            * beta[t+1])\n",
    "                    xi[i, :, t] = numer / denom\n",
    "  \n",
    "            # gamma_t(i) = P(q_t = S_i | O, hmm)\n",
    "            gamma = np.squeeze(np.sum(xi, axis=1))\n",
    "            # Need final gamma element for new B\n",
    "            prod = (alpha[-1] * beta[-1]).reshape((-1,1))\n",
    "            gamma = np.hstack((gamma,  prod / np.sum(prod))) # append one more to gamma!!!\n",
    "\n",
    "            new_pi = gamma.T[0]\n",
    "            new_a = np.sum(xi, axis=2) / np.sum(gamma[:, :-1], axis=1).reshape((-1,1))\n",
    "            new_b = np.array(b)\n",
    "\n",
    "            if False:\n",
    "                plt.figure()\n",
    "                plt.plot(gamma[1])\n",
    "                plt.ylim(-0.1,1.1)\n",
    "                plt.legend(('Probability State=1'))\n",
    "                plt.xlabel('Time')\n",
    "            \n",
    "            n_levels = self.b.shape[1]\n",
    "            sumgamma = np.sum(gamma, axis=1)\n",
    "            for lev in xrange(n_levels):\n",
    "                ix = obs == lev\n",
    "                new_b.T[lev] = np.sum(gamma[:, ix], axis=1) / sumgamma\n",
    "\n",
    "            self.pi[...] = new_pi\n",
    "            self.a[...] = new_a\n",
    "            self.b[...] = new_b\n",
    "        print(\"After P(obs) = %f\" % self.obs_probability(obs))\n",
    "\n",
    "N = 2\n",
    "M = 3\n",
    "pi = np.array([0.6, 0.4])\n",
    "a = np.array([[0.7, 0.3], [0.4, 0.6]])\n",
    "b = np.array([[0.5, 0.4, 0.1], [0.1, 0.3, 0.6]])\n",
    "obs = np.array([0, 1, 2])\n",
    "\n",
    "hmm = HMM(a, b, pi)\n",
    "fwd = hmm.forward(obs)\n",
    "bwd = hmm.backward(obs)\n",
    "posterior = fwd * bwd / np.sum(fwd[-1])\n",
    "# print fwd\n",
    "# print bwd\n",
    "# print posterior\n",
    "# print hmm.obs_probability([2])\n",
    "hmm.viterbi(obs)\n",
    "hmm.update([0, 0, 0], n_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print hmm.a\n",
    "print np.sum(hmm.a, axis=1)\n",
    "print hmm.b\n",
    "print np.sum(hmm.b, axis=1)\n",
    "print hmm.pi\n",
    "print np.sum(hmm.pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
