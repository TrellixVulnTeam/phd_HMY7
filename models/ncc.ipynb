{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell contains some imports that will be used\n",
    "# in the remainder of the notebook.\n",
    "\n",
    "import phd\n",
    "\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nengo\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from nengo.utils.matplotlib import rasterplot\n",
    "from nengo.utils.stdlib import Timer\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from IPython.display import Audio, display, SVG\n",
    "\n",
    "# Some plotting niceties\n",
    "phd.plots.setup(figsize=(5, 3.5))\n",
    "\n",
    "# Ensure TIMIT is extracted\n",
    "timit_path = \"~/phd_data/timit\"\n",
    "timit = phd.timit.TIMIT(timit_path)\n",
    "try:\n",
    "    timit.untar(os.path.expanduser(\"~/Dropbox/LDC93S1.tgz\"))\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "# Some general params\n",
    "utt = 'deadline'\n",
    "spkr = 'RRE0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature representations\n",
    "\n",
    "Here, we show extract both\n",
    "Mel-frequency Cepstral Coefficients (MFCCs)\n",
    "and Neural Cepstral Coefficients (NCCs)\n",
    "from a short audio sample from the TIMIT corpus.\n",
    "\n",
    "First, we must get the speech sample\n",
    "from the TIMIT corpus.\n",
    "We get a relatively interesting word\n",
    "that will demonstrate the changes\n",
    "in MFCCs and NCCs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timit = phd.timit.TIMIT(timit_path)\n",
    "timit.filefilt.spkr_id = spkr\n",
    "samples = timit.word_samples([utt])\n",
    "model = phd.sermo.AuditoryFeatures()\n",
    "model.audio = samples[utt][0]\n",
    "Audio(data=model.audio.ravel(), rate=phd.timit.TIMIT.fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract MFCCs\n",
    "using 25 ms audio frames\n",
    "advancing by 10 ms per timestep.\n",
    "The top plot is the raw MFCC,\n",
    "which has a wide range (see the color bar).\n",
    "We therefore z-score the MFCC to normalize it\n",
    "to a reasonable range in the bottom plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.mfcc.dt = 0.01\n",
    "x = model.mfcc()\n",
    "n_frames = x.shape[0]\n",
    "\n",
    "# Plot\n",
    "f, ax1, ax2 = phd.plots.plot_trajs(x, x, zscore=(False, True))\n",
    "f.suptitle(\"Features for utterance of '%s'\" % utt, fontsize='large')\n",
    "ax1.set_ylabel(\"MFCC\")\n",
    "ax2.set_ylabel(\"MFCC (z-scored)\")\n",
    "ax2.set_xlabel(\"Frame\")\n",
    "f.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "phd.plots.savefig(f, 'results', 'ncc-mfcc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare MFCCs and NCCs visually,\n",
    "we also extract MFCCs by advancing by 1 ms per timestep,\n",
    "which matches the natural timestep used by Nengo\n",
    "and therefore used for NCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.mfcc.dt = 0.001\n",
    "x = model.mfcc()\n",
    "\n",
    "# Plot\n",
    "f, ax1, ax2 = phd.plots.plot_trajs(x, x, zscore=(False, True))\n",
    "f.suptitle(\"Features for utterance of '%s'\" % utt, fontsize='large')\n",
    "ax1.set_ylabel(\"MFCC\")\n",
    "ax2.set_ylabel(\"MFCC (z-scored)\")\n",
    "ax2.set_xlabel(\"Frame\")\n",
    "f.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "phd.plots.savefig(f, 'results', 'ncc-mfcc-long')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract NCCs using a 1 ms simulation timestep,\n",
    "which is the norm for neural simulations in Nengo.\n",
    "Like for MFCCs, we show both the raw NCC\n",
    "and the z-scored NCC.\n",
    "In the case of NCCs, the raw result\n",
    "is already in a reasonable range (approximate -1 to 1)\n",
    "so z-scoring is not necessary,\n",
    "but is shown for visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = model.build(nengo.Network(seed=0))\n",
    "with net:\n",
    "    ihc_p = nengo.Probe(net.periphery.ihc, synapse=None)\n",
    "    an_in_p = nengo.Probe(net.periphery.an.input, synapse=None)\n",
    "    an_p = nengo.Probe(net.periphery.an.add_neuron_output(), synapse=None)\n",
    "    c_p = nengo.Probe(net.output, synapse=0.01)\n",
    "sim = nengo.Simulator(net, dt=0.001)\n",
    "sim.run(model.t_audio)\n",
    "\n",
    "# Plot\n",
    "t = sim.trange()\n",
    "t_ix = np.arange(0, t.size, 100)\n",
    "t_ix[1:] -= 1\n",
    "f, ax1, ax2 = phd.plots.plot_trajs(sim.data[c_p], sim.data[c_p], zscore=(False, True))\n",
    "f.suptitle(\"Features for utterance of '%s'\" % utt, fontsize='large')\n",
    "ax1.set_ylabel(\"NCC\")\n",
    "ax2.set_ylabel(\"NCC (z-scored)\")\n",
    "ax2.set_xticklabels(t_ix)\n",
    "ax2.set_xticklabels(t[t_ix])\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "f.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "phd.plots.savefig(f, 'results', 'ncc-ncc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better compare NCCs and MFCCs visually,\n",
    "we can shorten the NCC to have the same length\n",
    "as the MFCC generated by advancing the frame 10 ms\n",
    "per timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncc = phd.experiments.shorten(sim.data[c_p], n_frames=n_frames)\n",
    "\n",
    "# Plot\n",
    "t, t_ix = sim.trange(model.t_audio / n_frames), np.arange(0, n_frames, 10)\n",
    "t_ix[1:] -= 1\n",
    "f, ax1, ax2 = phd.plots.plot_trajs(ncc, ncc, zscore=(False, True))\n",
    "f.suptitle(\"Features for utterance of '%s'\" % utt, fontsize='large')\n",
    "ax1.set_ylabel(\"NCC\")\n",
    "ax2.set_ylabel(\"NCC (z-scored)\")\n",
    "ax2.set_xticks(t_ix)\n",
    "ax2.set_xticklabels(np.round(t[t_ix], 3))\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "f.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "phd.plots.savefig(f, 'results', 'ncc-ncc-short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the MFCCs and shortened NCCs visually.\n",
    "In general, they qualitative change at around the same times,\n",
    "though the NCC is somewhat delayed since it processes\n",
    "the audio online rather than with ideal discrete audio frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfcc = SVG(filename='../plots/results/ncc-mfcc.svg')\n",
    "ncc = SVG(filename='../plots/results/ncc-ncc-short.svg')\n",
    "display(mfcc, ncc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCC implementation\n",
    "\n",
    "The NCCs plotted above are the results of decoding\n",
    "the activity from neurons representing\n",
    "the cepstral coefficients.\n",
    "The cepstral coefficients are computed\n",
    "through connection weights between neurons representing\n",
    "the auditory filter outputs,\n",
    "which are similar to the neurons\n",
    "afferent the auditory nerve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVG(filename='../figures/implementation/ncc-network.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look more closely at the output of the auditory filters\n",
    "(i.e., the inner hair cell activity),\n",
    "the activity across the synapse between\n",
    "the inner hair cell and the auditory nerve neurons,\n",
    "and the spiking activity of the auditory nerve neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A peek into the neural implementation\n",
    "fig = plt.figure(figsize=(6, 10))\n",
    "\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "phd.plots.cochleogram(sim.data[ihc_p], sim.trange(), model.freqs, ax=ax, cbar=False)\n",
    "ax.set_title(\"Inner hair cell activity\")\n",
    "ax.set_xticks(())\n",
    "\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "phd.plots.cochleogram(sim.data[an_in_p], sim.trange(), model.freqs, ax=ax, cbar=False)\n",
    "ax.set_title(\"IHC-AN synaptic activity\")\n",
    "ax.set_xticks(())\n",
    "\n",
    "ax = plt.subplot(3, 1, 3)\n",
    "rasterplot(sim.trange(), sim.data[an_p])\n",
    "ax.set_title(\"Spiking AN neural activity\")\n",
    "ax.set_ylim(0, net.periphery.an.n_neurons * net.periphery.an.n_ensembles)\n",
    "ax.set_ylabel(\"Neuron\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "sns.despine()\n",
    "\n",
    "fig.tight_layout()\n",
    "phd.plots.savefig(fig, 'results', 'ncc-periphery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example,\n",
    "32 auditory filters are used with 8 neuron per auditory filter.\n",
    "Analogous networks with optimized parameters\n",
    "using fewer neurons per filter\n",
    "can achieve similar performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives\n",
    "\n",
    "As shown above, we can also compute the temporal derivative\n",
    "of the NCC in a neural network,\n",
    "which is a common augmentation to the MFCC feature vector.\n",
    "Below, we plot MFCCs and NCCs with their first and second\n",
    "temporal derivatives appended to the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timit = phd.timit.TIMIT(timit_path)\n",
    "timit.filefilt.spkr_id = spkr\n",
    "samples = timit.word_samples([utt])\n",
    "model = phd.sermo.AuditoryFeatures()\n",
    "model.audio = samples[utt][0]\n",
    "model.add_derivative('IntermediateDeriv')  # First derivative\n",
    "model.add_derivative('FeedforwardDeriv')  # Second derivative\n",
    "Audio(data=model.audio.ravel(), rate=phd.timit.TIMIT.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get MFCCs\n",
    "model.mfcc.dt = 0.01\n",
    "x = model.mfcc()\n",
    "\n",
    "# Plot\n",
    "f, ax1, ax2 = phd.plots.plot_trajs(x, x, zscore=(False, True))\n",
    "f.suptitle(\"Features for utterance of '%s'\" % utt, fontsize='large')\n",
    "ax1.set_ylabel(\"MFCC\")\n",
    "ax2.set_ylabel(\"MFCC (z-scored)\")\n",
    "ax2.set_xlabel(\"Frame\")\n",
    "f.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "phd.plots.savefig(f, 'results', 'ncc-mfcc-derivs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get NCCs\n",
    "net = model.build(nengo.Network(seed=0))\n",
    "with net:\n",
    "    ihc_p = nengo.Probe(net.periphery.ihc, synapse=None)\n",
    "    an_in_p = nengo.Probe(net.periphery.an.input, synapse=None)\n",
    "    an_p = nengo.Probe(net.periphery.an.add_neuron_output(), synapse=None)\n",
    "    c_p = nengo.Probe(net.output, synapse=0.01)\n",
    "sim = nengo.Simulator(net, dt=0.001)\n",
    "sim.run(model.t_audio)\n",
    "\n",
    "# Plot\n",
    "f, ax1, ax2 = phd.plots.plot_trajs(sim.data[c_p], sim.data[c_p], zscore=(False, True))\n",
    "f.suptitle(\"Features for utterance of '%s'\" % utt, fontsize='large')\n",
    "ax1.set_ylabel(\"NCC\")\n",
    "ax2.set_ylabel(\"NCC (z-scored)\")\n",
    "ax2.set_xticklabels(sim.trange())\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "f.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "phd.plots.savefig(f, 'results', 'ncc-ncc-derivs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfcc = SVG(filename='../plots/results/ncc-mfcc-derivs.svg')\n",
    "ncc = SVG(filename='../plots/results/ncc-ncc-derivs.svg')\n",
    "display(mfcc, ncc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification experiment\n",
    "\n",
    "In order to compare MFCCs and NCCs\n",
    "in terms of how speech-related sounds\n",
    "are separated in MFCC and NCC vector spaces,\n",
    "we classify feature vectors corresponding to\n",
    "pre-segmented speech samples using\n",
    "linear support vector machines.\n",
    "The metric reported in the end\n",
    "in classification correctness\n",
    "(i.e., the number of correctly predicted labels divided by\n",
    "the total number of samples).\n",
    "\n",
    "The following cell shows how to run a short experiment\n",
    "using only a small subset of the TIMIT corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not a full experiment, just showing how testing / training works\n",
    "# with a small data set.\n",
    "model = phd.sermo.AuditoryFeatures()\n",
    "expt = phd.experiments.AuditoryFeaturesExperiment(\n",
    "    model, phones=phd.timit.TIMIT.consonants)\n",
    "expt.seed = 20\n",
    "expt.timit.filefilt.region = 8\n",
    "expt.timit.filefilt.sex = 'F'\n",
    "expt.timit.filefilt.sent_type = 'I'\n",
    "key = expt.run()\n",
    "res = phd.experiments.AuditoryFeaturesResult.load(key)\n",
    "print(\"==== Summary ====\")\n",
    "print(\"MFCC training acc: %f\" % res.mfcc_train_acc)\n",
    "print(\"NCC training acc: %f\" % res.ncc_train_acc)\n",
    "print(\"MFCC testing acc: %f\" % res.mfcc_test_acc)\n",
    "print(\"NCC testing acc: %f\" % res.ncc_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting experimental results\n",
    "\n",
    "I ran these experiments with a larger subset\n",
    "of the TIMIT corpus, varying several parameters.\n",
    "For each parameter, I ran 10 experiments;\n",
    "for all conditions I show both\n",
    "a violin plot and a bar plot\n",
    "summarizing the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the phones used as input\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- Only vowel phones\n",
    "- Only consonant phones\n",
    "- All phones (including silence)\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- Consonants are most difficult to classify and have least separation between MFCC and NCC\n",
    "\n",
    "We therefore only look at consonants in later results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pargs = {'columns': [], 'vary': 'phones', 'filter_by': [], 'hue_order': [\"vowels\", \"consonants\", \"all\"]}\n",
    "\n",
    "def fix_label(l):\n",
    "    for t, label in zip(l.get_texts(), [\"Vowels\", \"Consonants\", \"All\"]):\n",
    "        t.set_text(label)\n",
    "\n",
    "v, b = phd.plots.ncc_accuracy(relative=False, **pargs)\n",
    "ax = b.get_axes()[0]\n",
    "ax.set_ylabel(\"Classification correctness\")\n",
    "l = ax.legend(title=\"\", bbox_to_anchor=(0.55, 0.9), bbox_transform=b.transFigure)\n",
    "fix_label(l)\n",
    "phd.plots.savefig(b, 'results', 'ncc-phones-acc-b')\n",
    "\n",
    "v, b = phd.plots.ncc_accuracy(relative=True, **pargs)\n",
    "ax = b.get_axes()[0]\n",
    "ax.set_ylabel(\"Relative classification correctness\")\n",
    "l = ax.legend(title=\"\")\n",
    "fix_label(l)\n",
    "phd.plots.savefig(b, 'results', 'ncc-phones-racc-b')\n",
    "\n",
    "t = phd.plots.ncc_time(**pargs)\n",
    "ax = t.get_axes()[0]\n",
    "l = ax.legend(loc='upper left', title=\"\")\n",
    "fix_label(l)\n",
    "phd.plots.savefig(t, 'results', 'ncc-phones-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying whether the feature is z-scored\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- z-scored\n",
    "- not z-scored\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- Variance goes way down for MFCCs when z-scored\n",
    "- NCCs are slightly better without z-scoring\n",
    "\n",
    "We therefore z-score MFCCs and not NCCs in future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v, b = phd.plots.ncc_accuracy(['zscore'], 'zscore', hue_order=['False', 'True'], relative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the number of derivatives used\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- no derivatives\n",
    "- first derivative\n",
    "- first and second derivatives\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- The first derivative improves MFCC accuracy significantly and has little effect on NCC accuracy.\n",
    "\n",
    "We therefore use 1 derivative for future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v, b = phd.plots.ncc_accuracy(relative=False,\n",
    "                              columns=['derivatives'],\n",
    "                              vary='derivatives',\n",
    "                              hue_order=['0', '1', '2'])\n",
    "ax = b.get_axes()[0]\n",
    "ax.legend(title=\"# of derivatives\", bbox_to_anchor=(0.57, 0.9), bbox_transform=b.transFigure)\n",
    "phd.plots.savefig(b, 'results', 'ncc-derivatives-acc-b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the temporal derivative model\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- Feedforward derivative model\n",
    "- Intermediate ensemble derivative model\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- The intermediate derivative model is significantly more accurate.\n",
    "\n",
    "We therefore only use the intermediate derivative model in future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phd.plots.ncc_accuracy(['derivtype'], 'derivtype',\n",
    "                       hue_order=['FeedforwardDeriv', 'IntermediateDeriv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the number of neurons per auditory filter\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- 1, 2, 4, 8, 16, or 32 neurons per filter\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- Plateaus around 8 neurons per filter.\n",
    "\n",
    "We therefore use 8 neurons per filter in future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = phd.plots.ncc_tsaccuracy(['periphery'], 'periphery')\n",
    "ax = t.get_axes()[0]\n",
    "ax.legend(loc='best', title=\"\")\n",
    "ax.set_xlabel(\"Neurons per periphery ensemble\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks((1, 2, 4, 8, 16, 32))\n",
    "ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "t.tight_layout()\n",
    "phd.plots.savefig(t, 'results', 'ncc-periphery-acc-t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the number of neurons per feature vector dimension\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- 1, 8, 12, 16, 32, 64 neurons\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- Accuracy improves steadily as more neurons are added\n",
    "- Simulation speed is drastically slower for more than 12 neurons\n",
    "\n",
    "We therefore use 12 neurons per feature vector dimension in future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = phd.plots.ncc_tsaccuracy(['feature'], 'feature')\n",
    "ax = t.get_axes()[0]\n",
    "ax.legend(loc='best', title=\"\")\n",
    "ax.set_xlabel(\"Neurons per feature ensemble\")\n",
    "t.tight_layout()\n",
    "phd.plots.savefig(t, 'results', 'ncc-feature-acc-t')\n",
    "\n",
    "t = phd.plots.ncc_time(['feature'], 'feature', [str(x) for x in [1, 8, 12, 16, 32, 64]])\n",
    "ax = t.get_axes()[0]\n",
    "ax.legend(loc='best', title=\"# of feature neurons\")\n",
    "phd.plots.savefig(t, 'results', 'ncc-feature-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the frame advance for MFCC\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- 10 ms, 5 ms, 1 ms\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- Best performance at 10 ms\n",
    "\n",
    "We therefore continue to use 10 ms frame advance in future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v, b = phd.plots.ncc_accuracy(\n",
    "    relative=False, columns=['dt'], vary='dt', hue_order=[\"0.010000\", \"0.005000\", \"0.001000\"])\n",
    "ax = b.get_axes()[0]\n",
    "l = ax.legend(title=\"MFCC dt\", loc='best')\n",
    "for t, label in zip(l.get_texts(), [\"10 ms\", \"5 ms\", \"1 ms\"]):\n",
    "    t.set_text(label)\n",
    "phd.plots.savefig(b, 'results', 'ncc-dt-acc-b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the auditory periphery model used\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- Gammatone filter\n",
    "- Log Gammachirp filter\n",
    "- Dual Resonance nonlinear filter\n",
    "- Compressive Gammachirp filter\n",
    "- Tan Carney auditory model\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- Generally, more complicated auditory periphery models performed better\n",
    "- More complicated auditory periphery models simulated slower\n",
    "- Gammatone is an outlier: least complex, best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['periphmodel', 'adaptive']\n",
    "porder = ['gammatone', 'log_gammachirp', 'dual_resonance', 'compressive_gammachirp', 'tan_carney']\n",
    "\n",
    "def fix_label(l):\n",
    "    labels = [\"Gammatone\", \"Log Gammachirp\", \"Dual Resonance\",\n",
    "              \"Compressive GC\", \"Tan Carney\"]\n",
    "    for t, label in zip(l.get_texts(), labels):\n",
    "        t.set_text(label)\n",
    "\n",
    "v, b = phd.plots.ncc_accuracy(columns, 'periphmodel', hue_order=porder, relative=True)\n",
    "ax = b.get_axes()[0]\n",
    "l = ax.legend(title=\"\", loc='best')\n",
    "fix_label(l)\n",
    "phd.plots.savefig(b, 'results', 'ncc-periphmodel-racc-b')\n",
    "\n",
    "t = phd.plots.ncc_time(columns, 'periphmodel', hue_order=porder)\n",
    "ax = t.get_axes()[0]\n",
    "l = ax.legend(title=\"\", loc='best')\n",
    "fix_label(l)\n",
    "phd.plots.savefig(t, 'results', 'ncc-periphmodel-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the neuron type used\n",
    "\n",
    "Conditions:\n",
    "\n",
    "- Normal LIF neuron\n",
    "- Adaptive LIF neuron\n",
    "\n",
    "Results summary:\n",
    "\n",
    "- No difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v, b = phd.plots.ncc_accuracy(columns, 'adaptive', hue_order=['False', 'True'], relative=True)\n",
    "ax = b.get_axes()[0]\n",
    "l = ax.legend(title=\"\", loc='upper left')\n",
    "for t, label in zip(l.get_texts(), [\"LIF\", \"Adaptive LIF\"]):\n",
    "    t.set_text(label)\n",
    "phd.plots.savefig(b, 'results', 'ncc-adaptive-racc-b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "Since this network is designed to mimic the human auditory system,\n",
    "and important question to ask is whether it will scale\n",
    "to the size of the human auditory system.\n",
    "We only use a small number of auditory filters\n",
    "and neurons associated with those filters.\n",
    "If we scale up, do we remain within known\n",
    "neuroanatomical constraints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def n_neurons(msg, model):\n",
    "    net = model.build()\n",
    "    nn = sum(e.n_neurons for e in net.all_ensembles)\n",
    "    print(\"=== %s ===\" % msg)\n",
    "    pneurons = model.freqs.size * model.periphery.neurons_per_freq\n",
    "    print(\"Periphery layer: %d freqs x %d neurons_per_freq = %d neurons\" % (\n",
    "        model.freqs.size, model.periphery.neurons_per_freq, pneurons))\n",
    "    cneurons = model.n_cepstra * model.cepstra.n_neurons\n",
    "    print(\"Feature layer: %d cepstra x %d neurons_per_cepstra = %d neurons\" % (\n",
    "        model.n_cepstra, model.cepstra.n_neurons, cneurons))\n",
    "    for i, deriv in enumerate(model.derivatives):\n",
    "        # Note! Assumes FeedforwardDeriv!\n",
    "        cneurons += model.n_cepstra * 2 * deriv.n_neurons\n",
    "        print(\"Derivative %d: %d cepstra x 2 x %d neurons_per_cepstra = %d neurons\" % (\n",
    "            (i+1), model.n_cepstra, deriv.n_neurons, model.n_cepstra * deriv.n_neurons))\n",
    "\n",
    "    assert pneurons + cneurons == nn\n",
    "    print(\"Total: %d neurons\" % nn)\n",
    "    print(\"%.3f mm^3 of cortex\" % (nn / 27000.))\n",
    "    print(\"\")\n",
    "\n",
    "model = phd.sermo.AuditoryFeatures()\n",
    "model.add_derivative()\n",
    "n_neurons(\"Default configuration\", model)\n",
    "model = phd.sermo.AuditoryFeatures()\n",
    "model.freqs = phd.filters.erbspace(20, 20000, 3500)\n",
    "model.periphery.neurons_per_freq = 20\n",
    "model.n_cepstra = 20\n",
    "model.cepstra.n_neurons = 50\n",
    "model.add_derivative(n_neurons=50)\n",
    "n_neurons(\"Conservative estimate\", model)\n",
    "model = phd.sermo.AuditoryFeatures()\n",
    "model.freqs = phd.filters.erbspace(20, 20000, 3500)\n",
    "model.periphery.neurons_per_freq = 40\n",
    "model.n_cepstra = 40\n",
    "model.cepstra.n_neurons = 200\n",
    "model.add_derivative(n_neurons=200)\n",
    "model.add_derivative(n_neurons=200)\n",
    "n_neurons(\"Generous estimate\", model);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
