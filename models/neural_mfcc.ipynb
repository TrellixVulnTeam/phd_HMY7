{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nengo\n",
    "from nengo.utils.matplotlib import rasterplot\n",
    "from nengo.utils.stdlib import Timer\n",
    "\n",
    "import phd\n",
    "\n",
    "# Some plotting niceties\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "def img(array):\n",
    "    plt.pcolormesh(array.T)\n",
    "    plt.ylim(top=array.shape[1])\n",
    "    plt.xlim(right=array.shape[0])\n",
    "    plt.colorbar()\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "timit_path = \"~/phd_data/timit\"\n",
    "timit = phd.timit.TIMIT(timit_path)\n",
    "try:\n",
    "    timit.untar(os.path.expanduser(\"~/Dropbox/LDC93S1.tgz\"))\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "if($(IPython.toolbar.selector.concat(' > #kill-run-first')).length == 0){\n",
    "  IPython.toolbar.add_buttons_group([\n",
    "    {\n",
    "      'label'   : 'kill and run-first',\n",
    "      'icon'    : 'fa fa-angle-double-down',\n",
    "      'callback': function(){\n",
    "        IPython.notebook.kernel.restart();\n",
    "        $(IPython.events).one('kernel_ready.Kernel', function(){\n",
    "          var idx = IPython.notebook.get_selected_index();\n",
    "          IPython.notebook.select(0);\n",
    "          IPython.notebook.execute_cell();\n",
    "          IPython.notebook.select(idx);\n",
    "        });\n",
    "      }\n",
    "    }\n",
    "  ], 'kill-run-first');\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timit = phd.timit.TIMIT(timit_path)\n",
    "timit.filefilt.spkr_id = \"CAG0\"\n",
    "samples = timit.word_samples(['she'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = phd.sermo.AudioFeatures()\n",
    "model.fs = timit.fs\n",
    "model.audio = samples['she'][0]\n",
    "model.freqs = phd.filters.erbspace(20, 4000, 64)\n",
    "model.n_cepstra = 13\n",
    "print(model.t_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get MFCCs\n",
    "model.mfcc.dt = 0.001\n",
    "x = model.mfcc()\n",
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img(x)\n",
    "plt.title(\"Mel-frequency cepstral coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "img(zscore(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get NCCs\n",
    "model.periphery.auditory_filter = phd.filters.gammatone(model.freqs)\n",
    "net = model.build()\n",
    "\n",
    "with net:\n",
    "    ihc_p = nengo.Probe(net.periphery.ihc, synapse=None)\n",
    "    an_in_p = nengo.Probe(net.periphery.an.input, synapse=None)\n",
    "    an_p = nengo.Probe(net.periphery.an.add_neuron_output(), synapse=None)\n",
    "    c_p = nengo.Probe(net.cepstra.output, synapse=0.01)\n",
    "\n",
    "sim = nengo.Simulator(net, dt=0.001)\n",
    "sim.run(model.t_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phd.plots.cochleogram(sim.data[ihc_p], sim.trange(), model.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phd.plots.cochleogram(sim.data[an_in_p], sim.trange(), model.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rasterplot(sim.trange(), sim.data[an_p])\n",
    "plt.ylim(0, net.periphery.an.n_neurons * net.periphery.an.n_ensembles);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img(sim.data[c_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img(zscore(sim.data[c_p], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phoneme classification with SVM\n",
    "\n",
    "Since the samples have to be the same length,\n",
    "we classify vowel and consonant phonemes separately.\n",
    "Also, we lengthen all samples to be the\n",
    "length of the longest sample\n",
    "with simple linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's start with differentiating two phonemes with whole test set\n",
    "timit = phd.timit.TIMIT(timit_path)\n",
    "audio = timit.phn_samples(timit.vowels, corpus=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert everything to MFCCs\n",
    "model = phd.sermo.AudioFeatures()\n",
    "model.fs = timit.fs\n",
    "model.freqs = phd.filters.erbspace(20, 4000, 64)\n",
    "model.n_cepstra = 13\n",
    "\n",
    "mfccs = {}\n",
    "for label in audio:\n",
    "    mfccs[label] = []\n",
    "    for sample in audio[label]:\n",
    "        model.audio = sample\n",
    "        mfccs[label].append(model.mfcc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lengthen all samples to the longest with linear interpolation.\n",
    "# We have to do this across all labels!\n",
    "from scipy.interpolate import interp1d\n",
    "i_mfccs = {}\n",
    "f_mfccs = {}\n",
    "\n",
    "n_frames = max(max(m.shape[0] for m in mfccs[label]) for label in audio)\n",
    "# n_frames = 611 / 13\n",
    "for label in audio:\n",
    "    i_mfccs[label] = []\n",
    "    f_mfccs[label] = []\n",
    "    for sample in mfccs[label]:\n",
    "        if sample.shape[0] <= 1:\n",
    "            # Too short -- just ignore it\n",
    "            continue\n",
    "        if sample.shape[0] < n_frames:\n",
    "            interp_x = np.linspace(0, n_frames, sample.shape[0])\n",
    "            f = interp1d(interp_x, sample, axis=0, assume_sorted=True)\n",
    "            sample = f(np.arange(n_frames))\n",
    "        # Now, we have each utterance as an array of shape (n_frames, n_features).\n",
    "        # We'll flatten these so that the SVM considers\n",
    "        # each utterance as a separate \"feature vector\"\n",
    "        i_mfccs[label].append(sample)\n",
    "        f_mfccs[label].append(sample.reshape(-1))\n",
    "        # Should also try z-scoring it\n",
    "print f_mfccs['oy'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prep X, y for SVM classification\n",
    "\n",
    "# SVM functions take as input\n",
    "#  X, shape (n_samples, n_features) holding the training samples,\n",
    "#  y, shape (n_samples,) with class labels (strings or integers)\n",
    "lbls = sorted(list(audio))\n",
    "X = np.vstack([np.vstack(f_mfccs[lbl]) for lbl in lbls])\n",
    "print X.shape\n",
    "y = []\n",
    "for lbl in lbls:\n",
    "    y.extend([lbl] * len(f_mfccs[lbl]))\n",
    "y = np.array(y)\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try LinearSVC (we're already in a high dimensional space)\n",
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "with Timer() as t:\n",
    "    clf.fit(X, y)\n",
    "print \"Took %s seconds\" % t.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict our training set to see how it does\n",
    "with Timer() as t:\n",
    "    pred_y = clf.predict(X)\n",
    "print \"Took %s seconds\" % t.duration\n",
    "train_acc = np.mean(pred_y == y)\n",
    "print \"Train accuracy: %0.3f\" % train_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
