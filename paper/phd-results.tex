\chapter{Evaluation and results}

%% ~15-30 pages

%% - adequacy, efficiency, productiveness, effectiveness
%%   (choose your criteria, state them clearly and justify them)
%% - be careful that you are using a fair measure, and that you are
%%   actually measuring what you claim to be measuring
%% - if comparing with previous techniques those techniques
%%   must be described in Chapter 2
%% - be honest in evaluation
%% - admit weaknesses

% For each model, have an initial section where subparts are
% tested to determine parameters for the full experiments

List of experiments (fill this in as you write other sections!!)

These should maybe be included in the methods?

??? try to reproduce nihms358264 as a recognition effect, not production

\section{Recognition system}

\subsection{Metrics}

Phoneme decode error rate

Pitch error rate

Volume error rate

\subsection{Experiments}

1. Do frequency interacting transformation matter?

- generate networks with N random transformations
  in preprocessing layer and collect the metrics

- systematically increase the number of interacting
  transformations and see if it matters
pp
2. Vowels: should we use temporal information or just
   the current moment's info?

3. Vowels: do diphthongs count?

- try having no categories for diphthongs and see if
  we can get the two components of it

- try having explicit diphthong categories and see
  if we get better at it

4. Separate vowel / consonant populations, or just one

- See if error rates differ

5. Consonants vs vowels:

- Vary the number of features and/or neurons and see
  how much is needed for equivalent error rates

  - Should error rates be normalized by the total number
    of possible outcomes?

6. Synthesized vs natural speech:

- How much easier is synthesized speech compared to natural?

7. Relative pitch experiment:

Find something from the literature to evaluate relative pitch...

8. Relative volume expt:

Find something from the literature to evaluate relative volume...

9. The usefulness of noise

- P. 65 of Kollier et al has a bunch of noise added in.
  Try injecting noise, see if it helps.

10. Preprocessing choices

- Pool or don't pool
- Use nonlinear derivative glides, or just pure derivatives

11. Phonemes or gestures

- Try decoding gestures instead of phonemes
- What's better / easier?

\section{Synthesis system}

\subsection{Metrics}

Speech intelligibility

RMSE between recognized and decoded speech?
Is that helpful?

Can use the recognition system to evaluate
this synthesis system relative to other
synthesis systems.
In a sense, this is one of the benefits
of this type of model.

Neural resources used

\subsection{Experiments}

1. Biologically plausible fluctuations.

- Ideal control methods have no variability, they hit things at the same time
- Record when consonantal closures / releases happen, show that there's
  a certain amount of variance
- Hopefully can show that this is similar to biology?

2. Oscillator / trajectory stability

- Show how accurate / fast the coupled oscillators can be
- Contrast to trajectory generation with Aaron's stuff
  (if that's possible)
  - Also contrast to trajectory gen with DMPs?

3. Scalability

- Take the control system and look at how much cortex (neurons, synapses)
  is taken up by each element (word, syllable, phoneme, etc).

- Extrapolate to human sized vocabularies, make sure it'll scale

- Show that if we had a separate oscillator / population
  for each word or syllable that this wouldn't scale

\section{Integrated system}

\subsection{Metrics}

\subsection{Experiments}

1. Shadowing proof of concept

- Show it works

??? more

4. Syllable learning proof of concept

- show it works

5. The effect of speed on syllable learning

- Slow it down. Should be better

% ----------------

\section{Neural Cepstral Coefficients}

\subsection{Evaluation}

We hypothesize that NCCs and DNCCs
are suitable feature vectors
for traditional ASR systems
and for more biologically plausible
models of the human speech system like Sermo.
In order to evaluate their effectiveness
in these situations,
we compare MFCCs with and without DCCs
and DDCCs to NCCs and DNCCs
on phoneme and word classification tasks.

??? choose an SVM implementation and
explain it here

??? we don't use dynamic time warping
ref DTWmyths.pdf

??? it's not clear if the derivatives will help
since the SVM should manage these,
so if they don't help then I will
just use the derivatives

??? Use TIMIT utterances

% From earlier iteration

% ??? Functional evaluation: can we decode downstream features?
% How well do we do compared to other systems?
% We don't have to do as well as them,
% but we have to do well enough that it's not ridiculous.

% ??? for phonemes: our gold standard is a set of labels
% over time with the proper phoneme.
% If the system categorizes to that label in that period,
% then it's correct. Or maybe what's more important
% is that the phonemes are all in the same order,
% and we also have some kind of timing information?

% ??? Neural evaluation: One thing that's commonly measured
% in auditory neuroscience is the spectro-temporal receptive field
% of auditory neurons. We can make these for our downstream feature
% neurons and compare them to published STRFs and see if they look similar.
% Note that it would be easy to make neurons that can replicate STRFs,
% as we would just use the temporal transformations that matter.
% But, we make our choice of transformations based on what would
% be best to decode certain features;
% being able to also replicate STRFs gives an indication that
% we made good choices, and that this system is engineered
% in a similar way to how the system developed and evolved (maybe?)

% ??? should we talk about the experiments from the results section here?

% ??? Nonsense CVCs: cite Allen 94;

% ``Typical ASR systems start with a `front-end' that transforms
% the speech signal into a `feature vector' which is then processed
% by a `back-end' classifier. These systems frequently place a
% heavy emphasis on word and language models as a method of
% increasing the recognition scores.''

% ``Because of confusion and misunderstanding based on
% coarticulation arguments, only a small amount of research
% has been done on the automatic recognition of nonsense CVCs.
% From the work of Fletcher and Steinberg, it should be clear
% that the real challenge in machine recognition today is
% human-like performance for phones and nonsense CVC
% under conditions of typical channel distortions.
% Since the human performance is well-known under
% these conditions [15], [19], nonsense CVCs
% represent an excellent database. Decreasing
% the error rates for these elementary signals would have
% a major impact on overall system performance and robustness.''

\section{Syllable sequencing and production}

\subsection{Evaluation}

??? compare original VTG -> audio to Nengo -> VTG -> audio

??? important: scaling. Show that adding new syllables
to the syllabary doesn't affect the voicing
of a given sequence; show how many neurons are added.

??? test how long of a sequence we can get to work

??? The goal of a syllable production system
is to generate an audio waveform
that is perceptually classified
by a listener as corresponding to
the intended syllable sequence.
While it is possible to quantify
whether this goal is achieved
by ...

??? For testing, we use gesture scores
for German syllables
provided by Bernd Kr\"{o}ger.

\section{Syllable recognition}
