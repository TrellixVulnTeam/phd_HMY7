\chapter{Evaluation and results}

%% ~15-30 pages

%% - adequacy, efficiency, productiveness, effectiveness
%%   (choose your criteria, state them clearly and justify them)
%% - be careful that you are using a fair measure, and that you are
%%   actually measuring what you claim to be measuring
%% - if comparing with previous techniques those techniques
%%   must be described in Chapter 2
%% - be honest in evaluation
%% - admit weaknesses

% For each model, have an initial section where subparts are
% tested to determine parameters for the full experiments

\section{Neural cepstral coefficients}

\subsection{Evaluation}

We hypothesize that NCCs and DNCCs
are suitable feature vectors
for traditional ASR systems
and for more biologically plausible
models of the human speech system like Sermo.
In order to evaluate their effectiveness
in these situations,
we compare MFCCs with and without DCCs
and DDCCs to NCCs and DNCCs
on phoneme and word classification tasks.

??? choose an SVM implementation and
explain it here

??? we don't use dynamic time warping
ref DTWmyths.pdf

??? it's not clear if the derivatives will help
since the SVM should manage these,
so if they don't help then I will
just use the derivatives

??? Use TIMIT utterances

% From earlier iteration

% ??? Functional evaluation: can we decode downstream features?
% How well do we do compared to other systems?
% We don't have to do as well as them,
% but we have to do well enough that it's not ridiculous.

% ??? for phonemes: our gold standard is a set of labels
% over time with the proper phoneme.
% If the system categorizes to that label in that period,
% then it's correct. Or maybe what's more important
% is that the phonemes are all in the same order,
% and we also have some kind of timing information?

% ??? Neural evaluation: One thing that's commonly measured
% in auditory neuroscience is the spectro-temporal receptive field
% of auditory neurons. We can make these for our downstream feature
% neurons and compare them to published STRFs and see if they look similar.
% Note that it would be easy to make neurons that can replicate STRFs,
% as we would just use the temporal transformations that matter.
% But, we make our choice of transformations based on what would
% be best to decode certain features;
% being able to also replicate STRFs gives an indication that
% we made good choices, and that this system is engineered
% in a similar way to how the system developed and evolved (maybe?)

% ??? should we talk about the experiments from the results section here?

% ??? Nonsense CVCs: cite Allen 94;

% ``Typical ASR systems start with a `front-end' that transforms
% the speech signal into a `feature vector' which is then processed
% by a `back-end' classifier. These systems frequently place a
% heavy emphasis on word and language models as a method of
% increasing the recognition scores.''

% ``Because of confusion and misunderstanding based on
% coarticulation arguments, only a small amount of research
% has been done on the automatic recognition of nonsense CVCs.
% From the work of Fletcher and Steinberg, it should be clear
% that the real challenge in machine recognition today is
% human-like performance for phones and nonsense CVC
% under conditions of typical channel distortions.
% Since the human performance is well-known under
% these conditions [15], [19], nonsense CVCs
% represent an excellent database. Decreasing
% the error rates for these elementary signals would have
% a major impact on overall system performance and robustness.''

\subsection{Experiments and results}

Hyperopt the main parameters

Consonants and vowels separate vs. together

\subsection{Scaling}

Give main metrics of the network (number of neurons, etc)
and discuss scaling

\section{Syllable sequencing and production}

\subsection{Evaluation}

RMSE between recognized and decoded speech?
Is that helpful?

??? compare original VTG -> audio to Nengo -> VTG -> audio

??? important: scaling. Show that adding new syllables
to the syllabary doesn't affect the voicing
of a given sequence; show how many neurons are added.

??? test how long of a sequence we can get to work

??? The goal of a syllable production system
is to generate an audio waveform
that is perceptually classified
by a listener as corresponding to
the intended syllable sequence.
While it is possible to quantify
whether this goal is achieved
by ...

??? For testing, we use gesture scores
for German syllables
provided by Bernd Kr\"{o}ger.

\subsection{Experiments and results}

Hyperopt the main parameters

1. Biologically plausible fluctuations.

- Ideal control methods have no variability, they hit things at the same time
- Record when consonantal closures / releases happen, show that there's
  a certain amount of variance
- Hopefully can show that this is similar to biology?

\subsection{Scaling}

Give main metrics of the network (number of neurons, etc)
and discuss scaling

- Take the control system and look at how much cortex (neurons, synapses)
  is taken up by each element (word, syllable, phoneme, etc).

- Extrapolate to human sized vocabularies, make sure it'll scale

- Show that if we had a separate oscillator / population
  for each word or syllable that this wouldn't scale

\section{Syllable recognition}

\subsection{Evaluation}

\subsection{Experiments and results}

Hyperopt the main parameters

\subsection{Scaling}

Give main metrics of the network (number of neurons, etc)
and discuss scaling
