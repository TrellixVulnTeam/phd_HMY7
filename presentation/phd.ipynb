{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Biologically inspired methods in speech recognition and synthesis: closing the loop\n",
    "\n",
    "## PhD defense presentation\n",
    "\n",
    "## February 4, 2016\n",
    "\n",
    "## Trevor Bekolay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "Spaun: very cool, but eyes and arms are lame.\n",
    "\n",
    "Speech is more natural interaction. Give it ears and a mouth.\n",
    "\n",
    "Taking ideas from:\n",
    "\n",
    "- Theoretical neuroscience (want to keep the good parts of Spaun)\n",
    "- Speech (can't just add ears and a mouth)\n",
    "- Machine learning (lots of existing work on speech recognition and synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goal: speech input and output\n",
    "\n",
    "Basic anatomy\n",
    "(ears, brain, vocal tract; sensory, cognitive, motor)\n",
    "\n",
    "Fig: basic anatomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What makes speech unique?\n",
    "\n",
    "Is it unique? People think so.\n",
    "Without getting into details,\n",
    "I can say that on the\n",
    "spatiotemporal spectrum,\n",
    "it is almost all the way toward temporal,\n",
    "which makes it somewhat unique.\n",
    "\n",
    "Fig: scale with temporal / spatial gradient\n",
    "(label speech recognition, speech production, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Closed-loop modeling\n",
    "\n",
    "Spaun sees and writes in one unified system.\n",
    "Most speech systems either do recognition or synthesis.\n",
    "If they do both, they use text as an intermediary;\n",
    "we obviously do not do this.\n",
    "Natural interactions necessitate closed loop models.\n",
    "\n",
    "Video: how to listen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previous work: DIVA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previous work: Kr√∂ger model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conceptual model: Sermo\n",
    "\n",
    "Fig: overall Sermo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conceptual model: Sermo\n",
    "\n",
    "Fig: Sermo with models implemented colored\n",
    "\n",
    "Introduce\n",
    "- Speech recognition (Neural Cepstral Coefficients)\n",
    "- Speech production (Trajectory generation)\n",
    "- Sensorimotor integraton (Trajectory classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural cepstral coefficients\n",
    "\n",
    "Fig: MFCC vs NCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Periphery models\n",
    "\n",
    "Fig: one of the figs from thesis (or all?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrete Cosine Transform\n",
    "\n",
    "Equation\n",
    "\n",
    "Fig: from thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Temporal derivatives\n",
    "\n",
    "Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "Fig: something to introduce speech samples,\n",
    "SVM, classification correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outperforms MFCC\n",
    "\n",
    "Fig: NCC vs MFCC with consonants, vowels, all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Slower than MFCC\n",
    "\n",
    "Fig: speed comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Can compare auditory periphery models\n",
    "\n",
    "Fig: aud periph comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable production\n",
    "\n",
    "Fig: subset of Sermo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VocalTractLab\n",
    "\n",
    "Fig or movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gesture scores\n",
    "\n",
    "Fig: gesture score from thesis\n",
    "\n",
    "Fig: trajectories from gesture scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic Movement Primitives (DMPs)\n",
    "\n",
    "Fig: some DMP stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example syllable sequence\n",
    "\n",
    "Fig: example\n",
    "\n",
    "Audio sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Result (TODO: which?)\n",
    "\n",
    "Fig: result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable classification\n",
    "\n",
    "Fig: temporal nature again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse DMPs\n",
    "\n",
    "Equation?\n",
    "\n",
    "Fig: some kind of intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example syllable classification\n",
    "\n",
    "Fig: example\n",
    "\n",
    "Audio paired with it would be ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contributions\n",
    "\n",
    "1. Sermo\n",
    "2. NCCs: outperform MFCCs, can be used with silicon cochleas\n",
    "3. Syllable production: can produce recognizable speech\n",
    "4. Syllable classification: can recognize speech from gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contributions\n",
    "\n",
    "1. Neural modelling: iDMP, temporal models, ears and a vocal tract\n",
    "2. Machine learning: NCC, test data set (tried this with RNNs for a bit, gave up)\n",
    "3. Speech: Sermo (computations underlying linguistic concepts), spiking neuron models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations & future work\n",
    "\n",
    "Fig: failure cases for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you\n",
    "\n",
    "List some thanks"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
