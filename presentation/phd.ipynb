{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "def video(fname, mimetype, width=\"100%\"):\n",
    "    from IPython.display import HTML\n",
    "    video_encoded = open(fname, \"rb\").read().encode(\"base64\")\n",
    "    video_tag = '<video controls alt=\"test\" src=\"data:video/{0};base64,{1}\" width=\"{2}\">'.format(\n",
    "        mimetype, video_encoded, width)\n",
    "    return HTML(data=video_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Biologically inspired methods in speech recognition and synthesis: closing the loop\n",
    "\n",
    "## PhD defense presentation\n",
    "\n",
    "## February 4, 2016\n",
    "\n",
    "## Trevor Bekolay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video('spaun.mp4', 'mp4', \"80%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Spaun: very cool, but eyes and arms are lame.\n",
    "\n",
    "Speech is more natural interaction. Give it ears and a mouth.\n",
    "\n",
    "Taking ideas from:\n",
    "\n",
    "- Theoretical neuroscience (want to keep the good parts of Spaun)\n",
    "- Speech (can't just add ears and a mouth)\n",
    "- Machine learning (lots of existing work on speech recognition and synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goal: speech input and output\n",
    "\n",
    "<img src=\"speech.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Our goal is to be able to build models using speech\n",
    "for input and output.\n",
    "First, we have to answer some basic questions,\n",
    "like are our ears doing,\n",
    "and how does that translate into internal representations\n",
    "used in the brain?\n",
    "How does an internal representation of\n",
    "a speech intention translate to the \n",
    "precise manipulations of the vocal tract\n",
    "that produce speech?\n",
    "These are the basic question we have to answer\n",
    "before we can do something like Spaun with speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What makes speech unique?\n",
    "\n",
    "<img src=\"spectrotemporal.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The techniques that are used in, for example,\n",
    "Spaun can't be easily applied to speech.\n",
    "These and other reasons have led\n",
    "some to posit that speech is a unique phenomenon\n",
    "that requires unique techniques.\n",
    "\n",
    "While that's not a debate I want to have,\n",
    "one important characteristic of speech\n",
    "is that speech has high temporal resolution\n",
    "and low spatial resolution.\n",
    "What I mean by that is...\n",
    "\n",
    "If we think about sensorimotor problems\n",
    "that humans face, ... (explain figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Closed-loop modeling\n",
    "\n",
    "<img src=\"perception-action.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Spaun sees and writes in one unified system.\n",
    "Most speech systems either do recognition or synthesis.\n",
    "If they do both, they use text as an intermediary;\n",
    "humans obviously do not do this.\n",
    "Natural interactions necessitate closed loop models.\n",
    "\n",
    "All animals live in a constant feedback loop with their environment.\n",
    "We perceive the environment,\n",
    "integrate that into our internal model of the world,\n",
    "and take actions that affect the environment.\n",
    "This process is constantly happening;\n",
    "we don't take turns with the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Closed-loop modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video('shadowing.mp4', 'mp4', \"80%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is partly why current\n",
    "speech recognition and synthesis systems\n",
    "are unnatural to us -- it feels turn-based,\n",
    "which is not how people talk.\n",
    "People talk over each other,\n",
    "speak in unison.\n",
    "There has been a push in second language learning lately\n",
    "to do this explicitly;\n",
    "it's a method called shadowing and it sounds like this.\n",
    "\n",
    "Very long term goal would be to have\n",
    "a computer shadow a human speaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conceptual model: Sermo\n",
    "\n",
    "<img src=\"sermo.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "What might be required to enable\n",
    "that kind of speech-based interaction?\n",
    "Sermo is my attempt at identifying the computations necessary.\n",
    "(Go through it...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conceptual model: Sermo\n",
    "\n",
    "1. Subsystems must operate in a continuous, online fashion.\n",
    "2. Subsystems must be implementable in\n",
    "   biologically plausible spiking neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In addition to implementing these computations,\n",
    "the way in which they are implemented matters.\n",
    "For a closed loop model with natural interactions,\n",
    "the subsystems in Sermo must operate continuously, and online.\n",
    "Additionally, they must be implementable in biologically plausible\n",
    "spiking neurons.\n",
    "(More, why, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conceptual model: Sermo\n",
    "\n",
    "<img src=\"sermo-implemented.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Introduce\n",
    "- Speech recognition (Neural Cepstral Coefficients)\n",
    "- Speech production (Trajectory generation)\n",
    "- Sensorimotor integraton (Trajectory classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural cepstral coefficients\n",
    "\n",
    "<img src=\"ncc.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural cepstral coefficients\n",
    "\n",
    "<img src=\"ncc-network.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Periphery models\n",
    "\n",
    "<img src=\"gammatone.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrete Cosine Transform\n",
    "\n",
    "\\begin{equation}\n",
    "  y_k = \\frac{x_0}{\\sqrt{N}} + \\sqrt{\\frac{2}{N}} \\sum_{n=1}^{N-1}\n",
    "  x_n \\cos \\left( \\frac{\\pi}{N} n \\left( k + \\frac{1}{2} \\right) \\right)\n",
    "  \\text{ for } 0 \\le k < N,\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align}\n",
    "  \\mathbf{k} &= \\left[ 0, 1, \\ldots, N-1 \\right] & 1 \\times N \\text{ vector} \\nonumber \\\\\n",
    "  \\mathbf{s} &= \\left[ \\sqrt{2}, 1, 1, \\ldots, 1 \\right] & 1 \\times N \\text{ vector} \\nonumber \\\\\n",
    "  \\mathbf{T} &= \\sqrt{2}{N} \\, \\mathbf{s} \\circ \\cos \\left( \\frac{\\pi}{N} \\left(\n",
    "    \\mathbf{k} + \\frac{1}{2} \\right) \\otimes \\mathbf{k} \\right)\n",
    "    & N \\times N \\text{ matrix} \\nonumber \\\\\n",
    "  \\mathbf{y} &= \\mathbf{T}\\mathbf{x} & N \\times 1 \\text{ vector}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example NCC\n",
    "\n",
    "<img src=\"mfcc-ncc.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "<image src=\"ncc-eval-train.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "<image src=\"ncc-eval-test.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "What we're measuring is \"classification correctness,\"\n",
    "which is the proportion of predicted phoneme labels\n",
    "that are correct\n",
    "(that's it, since samples are pre-segmented)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NCCs outperform MFCCs\n",
    "\n",
    "<img src=\"ncc-phones.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NCCs are computationally expensive\n",
    "\n",
    "<img src=\"ncc-phones-time\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Enables comparing periphery models\n",
    "\n",
    "<img src=\"ncc-periphmodel-racc-b.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable production\n",
    "\n",
    "<img src=\"sermo-implemented.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VocalTractLab\n",
    "\n",
    "<img src=\"vtl.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gesture scores\n",
    "\n",
    "<img src=\"gs.svg\">\n",
    "\n",
    "<img src=\"gs-traj.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable production network\n",
    "\n",
    "<img src=\"prod-network.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example syllable sequence\n",
    "\n",
    "<img src=\"prod-good.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Audio sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(\"original.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(\"model.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Enables speech of varying speeds\n",
    "\n",
    "<img src=\"prod-freq.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable classification\n",
    "\n",
    "<img src=\"sermo-implemented.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse DMPs\n",
    "\n",
    "<img src=\"idmp.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example syllable classification\n",
    "\n",
    "<img src=\"recog-good.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Operates online with no resets\n",
    "\n",
    "<img src=\"recog-sequence_len.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations & future work\n",
    "\n",
    "<img src=\"sermo-implemented.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NCC\n",
    "\n",
    "- Slow! Experiment with silicon cochleas.\n",
    "- Implement in continuous speech recognition system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable production\n",
    "\n",
    "- Does not handle long sequences well.\n",
    "- Does not handle large syllabaries well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Syllable classification\n",
    "\n",
    "- Does not handle varying speech speeds well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contributions\n",
    "\n",
    "<ol>\n",
    "<li>Speech: Sermo, spiking neuron models</li>\n",
    "<li class=\"fragment\">Machine learning: NCC, gesture score data set</li>\n",
    "<li class=\"fragment\">Neural modeling: iDMP, linking temporal inputs/outputs to Spaun, ears and vocal tract</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you\n",
    "\n",
    "List some thanks or screenshot of acknowledgements?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
