{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nengo\n",
    "import nengo.utils.numpy as npext\n",
    "import nengo_ocl\n",
    "import nengo_gui.ipython\n",
    "\n",
    "import phd\n",
    "\n",
    "# Some plotting niceties\n",
    "plt.rc('figure', figsize=(10, 8))\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 25000.\n",
    "dt = 1. / fs\n",
    "\n",
    "def plot_sound(process, t, dt):\n",
    "    plt.figure()\n",
    "    plt.plot(process.trange(t, dt=dt), process.run(t, dt=dt))\n",
    "    plt.xlim(right=t)\n",
    "    sns.despine()\n",
    "\n",
    "plot_sound(phd.sounds.WavFile('speech.wav'), 0.667, dt)\n",
    "plot_sound(phd.sounds.WhiteNoise(), 0.1, dt)\n",
    "plot_sound(phd.sounds.Tone(250), 0.1, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditory periphery\n",
    "\n",
    "Making heavy use of [Brian hears](http://www.briansimulator.org/docs/hears.html),\n",
    "but should also investigate other periphery models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WhiteNoise()\n",
    "aud_filter = phd.filters.dual_resonance(freqs)\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs)\n",
    "ihc_p, an_in_p, an_p = model.probe_periphery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nengo.utils.matplotlib import rasterplot\n",
    "\n",
    "dt = 1. / freqs.max()\n",
    "print(\"dt=%.5f\" % dt)\n",
    "sim = nengo.Simulator(model, dt=dt*.5)\n",
    "sim.run(0.1)\n",
    "\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[ihc_p], freqs, sim.trange())\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[an_in_p], freqs, sim.trange())\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[an_p])\n",
    "plt.ylim(0, model.an.n_neurons * model.an.n_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in model.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WavFile('speech.wav')\n",
    "aud_filter = phd.filters.dual_resonance(freqs)\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs)\n",
    "# TODO: Vary tau_highpass and radius\n",
    "model.add_derivative(n_neurons=30, delay=0.01, tau_highpass=0.05)\n",
    "with model:\n",
    "    ihc_p = nengo.Probe(model.ihc, synapse=None)\n",
    "    an_p = nengo.Probe(model.an.output, synapse=0.01)\n",
    "d_p = model.probe_derivative(delay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / freqs.max()\n",
    "sim = nengo.Simulator(model, dt=dt*.5)\n",
    "sim.run(0.667)\n",
    "\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[ihc_p], freqs, sim.trange())\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[an_p], freqs, sim.trange())\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[d_p], freqs, sim.trange())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in model.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
