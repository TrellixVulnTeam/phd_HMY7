{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nengo\n",
    "import nengo.utils.numpy as npext\n",
    "# import nengo_ocl\n",
    "import nengo_gui.ipython\n",
    "\n",
    "import phd\n",
    "\n",
    "# Some plotting niceties\n",
    "plt.rc('figure', figsize=(8, 5))\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "if($(IPython.toolbar.selector.concat(' > #kill-run-first')).length == 0){\n",
    "  IPython.toolbar.add_buttons_group([\n",
    "    {\n",
    "      'label'   : 'kill and run-first',\n",
    "      'icon'    : 'fa fa-angle-double-down',\n",
    "      'callback': function(){\n",
    "        IPython.notebook.kernel.restart();\n",
    "        $(IPython.events).one('kernel_ready.Kernel', function(){\n",
    "          var idx = IPython.notebook.get_selected_index();\n",
    "          IPython.notebook.select(0);\n",
    "          IPython.notebook.execute_cell();\n",
    "          IPython.notebook.select(idx);\n",
    "        });\n",
    "      }\n",
    "    }\n",
    "  ], 'kill-run-first');\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 25000.\n",
    "dt = 1. / fs\n",
    "\n",
    "def plot_sound(process, t, dt):\n",
    "    plt.figure()\n",
    "    plt.plot(process.trange(t, dt=dt), process.run(t, dt=dt))\n",
    "    plt.xlim(right=t)\n",
    "    sns.despine()\n",
    "\n",
    "plot_sound(phd.sounds.WavFile('speech.wav'), 0.667, dt)\n",
    "# plot_sound(phd.sounds.WhiteNoise(), 0.1, dt)\n",
    "# plot_sound(phd.sounds.Tone(250), 0.1, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditory periphery\n",
    "\n",
    "Making heavy use of [Brian hears](http://www.briansimulator.org/docs/hears.html),\n",
    "but should also investigate other periphery models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WhiteNoise()\n",
    "aud_filter = phd.filters.gammatone(freqs)\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs)\n",
    "\n",
    "with model:\n",
    "    ihc_p = nengo.Probe(model.ihc, synapse=None)\n",
    "    an_in_p = nengo.Probe(model.an.input, synapse=None)\n",
    "    an_p = nengo.Probe(model.an.add_neuron_output(), synapse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nengo.utils.matplotlib import rasterplot\n",
    "\n",
    "dt = 1. / freqs.max()\n",
    "print(\"dt=%.5f\" % dt)\n",
    "sim = nengo.Simulator(model, dt=dt*.5)\n",
    "sim.run(0.1)\n",
    "\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[ihc_p], sim.trange(), freqs)\n",
    "plt.figure()\n",
    "phd.plots.cochleogram(sim.data[an_in_p], sim.trange(), freqs)\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[an_p])\n",
    "plt.ylim(0, model.an.n_neurons * model.an.n_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in model.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WavFile('speech.wav')\n",
    "aud_filter = phd.filters.gammatone(freqs)\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs, middle_ear=True)\n",
    "model.add_derivative(n_neurons=30, delay=0.01, tau_highpass=0.05)\n",
    "model.add_integrator(n_neurons=20, tau=0.2)\n",
    "\n",
    "with model:\n",
    "    ihc_p = nengo.Probe(model.ihc, synapse=None, sample_every=0.001)\n",
    "    an_p = nengo.Probe(model.an.output, synapse=0.01, sample_every=0.001)\n",
    "    d_p = nengo.Probe(model.derivatives[0.01], synapse=0.01, sample_every=0.001)\n",
    "    i_p = nengo.Probe(model.integrators[0.2], synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / freqs.max()\n",
    "sim = nengo.Simulator(model, dt=dt*.5)\n",
    "sim.run(0.667)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "phd.plots.cochleogram(sim.data[ihc_p], sim.trange(0.001), freqs)\n",
    "plt.subplot(2, 2, 2)\n",
    "phd.plots.cochleogram(sim.data[an_p], sim.trange(0.001), freqs)\n",
    "plt.subplot(2, 2, 3)\n",
    "phd.plots.cochleogram(sim.data[d_p], sim.trange(0.001), freqs)\n",
    "plt.subplot(2, 2, 4)\n",
    "phd.plots.cochleogram(sim.data[i_p], sim.trange(0.001), freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in model.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_eval_points(model, pool=None):\n",
    "    with model:\n",
    "        an_p = nengo.Probe(model.an.output, synapse=0.01, sample_every=0.001)\n",
    "        c_p = nengo.Probe(model.derivatives[cons_delay], synapse=0.01, sample_every=0.001)\n",
    "        v_p = nengo.Probe(model.derivatives[vowel_delay], synapse=0.01, sample_every=0.001)\n",
    "    dt = 1. / freqs.max()\n",
    "    sim = nengo.Simulator(model, dt=dt*.5)\n",
    "    sim.run(0.667)\n",
    "    vowel = np.hstack([sim.data[an_p], sim.data[v_p]])\n",
    "    consonant = np.hstack([sim.data[an_p], sim.data[c_p]])\n",
    "    if pool is not None:\n",
    "        d = vowel.shape[1] // pool\n",
    "        pooled_v = np.zeros((vowel.shape[0], d))\n",
    "        pooled_c = np.zeros((consonant.shape[0], d))\n",
    "        for p in range(d):\n",
    "            pooled_v[:, p] = np.sum(vowel[:, p*pool:(p+1)*pool], axis=1)\n",
    "            pooled_c[:, p] = np.sum(consonant[:, p*pool:(p+1)*pool], axis=1)\n",
    "        vowel = pooled_v\n",
    "        consonant = pooled_c\n",
    "    for probe in (an_p, c_p, v_p):\n",
    "        model.probes.remove(probe)\n",
    "    return vowel, consonant, sim.trange(0.001)\n",
    "\n",
    "# hack for now: let's just manually specify\n",
    "# phonemes: e n schwa r j i z\n",
    "# vowel: 0.05 e 0.145 schwa 0.27 i end\n",
    "# consonant: 0.11 n 0.2 r 0.263 j 0.5 z\n",
    "def vowel_targets(t):\n",
    "    # e, schwa, i\n",
    "    out = np.zeros((t.size, 3))\n",
    "    out[(t >= 0.05) & (t < 0.145), 0] = 1\n",
    "    out[(t >= 0.145) & (t < 0.27), 1] = 1\n",
    "    out[t >= 0.27, 2] = 1\n",
    "    return out\n",
    "\n",
    "def cons_targets(t):\n",
    "    # n, r, j, z\n",
    "    out = np.zeros((t.size, 4))\n",
    "    out[(t >= 0.11) & (t < 0.2), 0] = 1\n",
    "    out[(t >= 0.2) & (t < 0.263), 1] = 1\n",
    "    out[(t >= 0.263) & (t < 0.5), 2] = 1\n",
    "    out[t >= 0.5, 3] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WavFile('speech.wav')\n",
    "aud_filter = phd.filters.gammatone(freqs)\n",
    "cons_delay = 0.075\n",
    "vowel_delay = 0.03\n",
    "# Note: no integrator here\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs, middle_ear=True)\n",
    "model.add_derivative(n_neurons=30, delay=cons_delay)\n",
    "model.add_derivative(n_neurons=30, delay=vowel_delay)\n",
    "\n",
    "vowel_ep, cons_ep, t = get_eval_points(model)\n",
    "_, vowel = model.add_phoneme_detector(15, vowel_ep, vowel_targets(t), [vowel_delay])\n",
    "_, cons = model.add_phoneme_detector(15, cons_ep, cons_targets(t), [cons_delay])\n",
    "\n",
    "with model:\n",
    "    vowel_p = nengo.Probe(vowel, synapse=0.01, sample_every=0.001)\n",
    "    cons_p = nengo.Probe(cons, synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / freqs.max()\n",
    "sim = nengo.Simulator(model, dt=dt*.5)\n",
    "sim.run(0.667)\n",
    "t = sim.trange(0.001)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, sim.data[vowel_p])\n",
    "plt.xlim(right=t[-1])\n",
    "plt.legend([\"e\", \"schwa\", \"i\"])\n",
    "sns.despine()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, sim.data[cons_p])\n",
    "plt.xlim(right=t[-1])\n",
    "plt.legend([\"n\", \"r\", \"j\", \"z\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in model.all_ensembles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WavFile('speech.wav')\n",
    "aud_filter = phd.filters.gammatone(freqs)\n",
    "cons_delay = 0.075\n",
    "vowel_delay = 0.03\n",
    "pool = 4\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs, middle_ear=True)\n",
    "model.add_derivative(n_neurons=30, delay=cons_delay)\n",
    "model.add_derivative(n_neurons=30, delay=vowel_delay)\n",
    "\n",
    "vowel_ep, cons_ep, t = get_eval_points(model, pool=pool)\n",
    "_, vowel = model.add_hierarchical_detector(15, vowel_ep, vowel_targets(t), [vowel_delay], pool=pool)\n",
    "_, cons = model.add_hierarchical_detector(15, cons_ep, cons_targets(t), [cons_delay], pool=pool)\n",
    "\n",
    "with model:\n",
    "    vowel_p = nengo.Probe(vowel, synapse=0.01, sample_every=0.001)\n",
    "    cons_p = nengo.Probe(cons, synapse=0.01, sample_every=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / freqs.max()\n",
    "sim = nengo.Simulator(model, dt=dt*.5)\n",
    "sim.run(0.667)\n",
    "t = sim.trange(0.001)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, sim.data[vowel_p])\n",
    "plt.xlim(right=t[-1])\n",
    "plt.legend([\"e\", \"schwa\", \"i\"])\n",
    "sns.despine()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, sim.data[cons_p])\n",
    "plt.xlim(right=t[-1])\n",
    "plt.legend([\"n\", \"r\", \"j\", \"z\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in model.all_ensembles))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
