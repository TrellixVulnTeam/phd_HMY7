{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from JSAnimation import IPython_display\n",
    "from skspeech.synthesis import kroger as kr\n",
    "\n",
    "import nengo\n",
    "import nengo.utils.numpy as npext\n",
    "import nengo_gui.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some plotting niceties\n",
    "plt.rc('figure', figsize=(10, 8))\n",
    "\n",
    "def shiftedcmap(cmap, start=0, midpoint=0.5, stop=1.0, name='shiftedcmap'):\n",
    "    \"\"\"Offset the 'center' of a colormap.\n",
    "\n",
    "    Useful for data with a negative min and positive max and you\n",
    "    want the middle of the colormap's dynamic range to be at zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmap : The matplotlib colormap to be altered\n",
    "    start : Offset from lowest point in the colormap's range.\n",
    "            Defaults to 0.0 (no lower ofset). Should be between\n",
    "            0.0 and `midpoint`.\n",
    "    midpoint : The new center of the colormap. Defaults to \n",
    "               0.5 (no shift). Should be between 0.0 and 1.0. In\n",
    "               general, this should be  1 - vmax/(vmax + abs(vmin))\n",
    "               For example if your data range from -15.0 to +5.0 and\n",
    "               you want the center of the colormap at 0.0, `midpoint`\n",
    "              should be set to  1 - 5/(5 + 15)) or 0.75\n",
    "    stop : Offset from highets point in the colormap's range.\n",
    "           Defaults to 1.0 (no upper ofset). Should be between\n",
    "           `midpoint` and 1.0.\n",
    "\n",
    "    From http://stackoverflow.com/questions/7404116/defining-the-midpoint-of-a-colormap-in-matplotlib\n",
    "    \"\"\"\n",
    "    cdict = {\n",
    "        'red': [],\n",
    "        'green': [],\n",
    "        'blue': [],\n",
    "        'alpha': []\n",
    "    }\n",
    "\n",
    "    # regular index to compute the colors\n",
    "    reg_index = np.linspace(start, stop, 257)\n",
    "\n",
    "    # shifted index to match the data\n",
    "    shift_index = np.hstack([\n",
    "        np.linspace(0.0, midpoint, 128, endpoint=False), \n",
    "        np.linspace(midpoint, 1.0, 129, endpoint=True)\n",
    "    ])\n",
    "\n",
    "    for ri, si in zip(reg_index, shift_index):\n",
    "        r, g, b, a = cmap(ri)\n",
    "        cdict['red'].append((si, r, r))\n",
    "        cdict['green'].append((si, g, g))\n",
    "        cdict['blue'].append((si, b, b))\n",
    "        cdict['alpha'].append((si, a, a))\n",
    "\n",
    "    newcmap = matplotlib.colors.LinearSegmentedColormap(name, cdict)\n",
    "    plt.register_cmap(cmap=newcmap)\n",
    "\n",
    "    return newcmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditory periphery\n",
    "\n",
    "Making heavy use of [Brian hears](http://www.briansimulator.org/docs/hears.html),\n",
    "but should also investigate other periphery models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brian filter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import brian_no_units  # For speed\n",
    "import brian as br\n",
    "import brian.hears as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def whitenoise_sound():\n",
    "    sound = bh.whitenoise(100*br.ms).ramp()\n",
    "    sound.level = 50*bh.dB\n",
    "    sound.samplerate = 50*br.kHz\n",
    "    return sound\n",
    "\n",
    "def tone_sound():\n",
    "    sound = bh.tone(500*br.Hz, 100*br.ms).ramp()\n",
    "    sound.level = 50*bh.dB\n",
    "    sound.samplerate = 50*br.kHz\n",
    "    return sound\n",
    "\n",
    "def cochleogram(gt_mon, time=None):\n",
    "    cmap = plt.cm.RdBu\n",
    "    if gt_mon.min() >= 0.0:\n",
    "        cmap = plt.cm.Blues\n",
    "    elif not np.allclose(gt_mon.max() + gt_mon.min(), 0, atol=1e-5):\n",
    "        midpoint = np.abs(gt_mon.min()) / (gt_mon.max() - gt_mon.min())\n",
    "        cmap = shiftedcmap(cmap, midpoint=midpoint)\n",
    "\n",
    "    duration = time[-1] if time is not None else sound.duration / br.ms\n",
    "    plt.imshow(gt_mon.T, aspect='auto', origin='lower left', cmap=cmap,\n",
    "               extent=(0, duration, cf[0], cf[-1]))\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.colorbar()\n",
    "\n",
    "sound = whitenoise_sound()\n",
    "# sound = tone_sound()\n",
    "n_cf = n_center_frequencies = 200\n",
    "cf = center_frequencies = bh.erbspace(100*br.Hz, 1000*br.Hz, n_center_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gammatone\n",
    "from brian.hears.filtering.tan_carney import ZhangSynapseRate\n",
    "\n",
    "b1 = 1.019  # factor determining the time constant of the filters\n",
    "\n",
    "# Apply middle ear filter?\n",
    "if False:\n",
    "    gammatone = bh.Gammatone(bh.MiddleEar(sound), center_frequencies, b=b1)\n",
    "else:\n",
    "    gammatone = bh.Gammatone(sound, center_frequencies, b=b1)\n",
    "\n",
    "gt_mon = gammatone.process()\n",
    "cochleogram(gt_mon)\n",
    "plt.title('Cochleogram')\n",
    "\n",
    "# half wave rectify and compress it with a 1/3 power law\n",
    "plt.figure()\n",
    "ihc = bh.FunctionFilterbank(gammatone, lambda x: 3 * np.clip(x, 0, np.inf) ** (1. / 3.))\n",
    "cochleogram(ihc.process())\n",
    "plt.title('IHC activity')\n",
    "\n",
    "# Get AN fiber rates\n",
    "plt.figure()\n",
    "syn = ZhangSynapseRate(ihc, cf)\n",
    "s_mon = br.StateMonitor(syn, 's', record=True, clock=syn.clock)\n",
    "net = br.Network(syn, s_mon)\n",
    "net.run(sound.duration)\n",
    "cochleogram(s_mon.values.T)\n",
    "plt.title('AN spike rates')\n",
    "\n",
    "# Let's see spikes now...\n",
    "plt.figure()\n",
    "syn = bh.ZhangSynapse(ihc, cf)\n",
    "sp_mon = br.SpikeMonitor(syn)\n",
    "net = br.Network(syn, sp_mon)\n",
    "net.run(sound.duration)\n",
    "br.raster_plot(sp_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Approximate Gammatone\n",
    "\n",
    "# bandwidth of the filters (different in each channel)\n",
    "bw = 10**(0.037+0.785*np.log10(center_frequencies))\n",
    "gammatone = bh.ApproximateGammatone(sound, center_frequencies, bw, order=3)\n",
    "gt_mon = gammatone.process()\n",
    "cochleogram(gt_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log Gammachirp\n",
    "\n",
    "c1 = -2.96 # glide slope\n",
    "b1 = 1.81  # factor determining the time constant of the filters\n",
    "gamma_chirp = bh.LogGammachirp(sound, cf, c=c1, b=b1)\n",
    "gamma_chirp_mon = gamma_chirp.process()\n",
    "cochleogram(gamma_chirp_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Gammachirp\n",
    "\n",
    "c = 0.0 # glide slope\n",
    "time_constant = np.linspace(3, 0.3, n_center_frequencies) * br.ms\n",
    "gamma_chirp = bh.LinearGammachirp(sound, center_frequencies, time_constant, c)\n",
    "gamma_chirp_mon = gamma_chirp.process()\n",
    "cochleogram(gamma_chirp_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tan & Carney\n",
    "reproduce_paper_figs = False\n",
    "if reproduce_paper_figs:\n",
    "    bh.set_default_samplerate(50*br.kHz)\n",
    "    sample_length = 1 / bh.get_samplerate(None)\n",
    "    cf = 1000 * br.Hz\n",
    "\n",
    "    print 'Testing click response'\n",
    "    duration = 25 * br.ms\n",
    "    levels = [40, 60, 80, 100, 120]\n",
    "    # a click of two samples\n",
    "    tones = bh.Sound([bh.Sound.sequence([bh.click(sample_length*2, peak=level*bh.dB),\n",
    "                                         bh.silence(duration=duration - sample_length)])\n",
    "                      for level in levels])\n",
    "    ihc = bh.TanCarney(bh.MiddleEar(tones), [cf] * len(levels), update_interval=1)\n",
    "    syn = bh.ZhangSynapse(ihc, cf)\n",
    "    s_mon = br.StateMonitor(syn, 's', record=True, clock=syn.clock)\n",
    "    R_mon = br.StateMonitor(syn, 'R', record=True, clock=syn.clock)\n",
    "    spike_mon = br.SpikeMonitor(syn)\n",
    "    net = br.Network(syn, s_mon, R_mon, spike_mon)\n",
    "    net.run(duration * 1.5)\n",
    "\n",
    "    for idx, level in enumerate(levels):\n",
    "        plt.figure(1)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(s_mon.times / br.ms, s_mon[idx])\n",
    "        plt.xlim(0, 25)\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.ylabel('Sp/sec')\n",
    "        plt.text(15, np.nanmax(s_mon[idx])/2., 'Peak SPL=%s SPL' % str(level*bh.dB));\n",
    "        ymin, ymax = plt.ylim()\n",
    "        if idx == 0:\n",
    "            plt.title('Click responses')\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(R_mon.times / br.ms, R_mon[idx])\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.text(15, np.nanmax(s_mon[idx])/2., 'Peak SPL=%s SPL' % str(level*bh.dB));\n",
    "        plt.ylim(ymin, ymax)\n",
    "        if idx == 0:\n",
    "            plt.title('Click responses (with spikes and refractoriness)')\n",
    "        plt.plot(spike_mon.spiketimes[idx] / br.ms,\n",
    "             np.ones(len(spike_mon.spiketimes[idx])) * np.nanmax(R_mon[idx]), 'rx')\n",
    "\n",
    "    print 'Testing tone response'\n",
    "    br.reinit_default_clock()\n",
    "    duration = 60*br.ms\n",
    "    levels = [0, 20, 40, 60, 80]\n",
    "    tones = bh.Sound([bh.Sound.sequence([bh.tone(cf, duration).atlevel(level*bh.dB).ramp(when='both',\n",
    "                                                                                         duration=10*br.ms,\n",
    "                                                                                         inplace=False),\n",
    "                                         bh.silence(duration=duration/2)])\n",
    "                      for level in levels])\n",
    "    ihc = bh.TanCarney(bh.MiddleEar(tones), [cf] * len(levels), update_interval=1)\n",
    "    syn = bh.ZhangSynapse(ihc, cf)\n",
    "    s_mon = br.StateMonitor(syn, 's', record=True, clock=syn.clock)\n",
    "    R_mon = br.StateMonitor(syn, 'R', record=True, clock=syn.clock)\n",
    "    spike_mon = br.SpikeMonitor(syn)\n",
    "    net = br.Network(syn, s_mon, R_mon, spike_mon)\n",
    "    net.run(duration * 1.5)\n",
    "    for idx, level in enumerate(levels):\n",
    "        plt.figure(3)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(s_mon.times / br.ms, s_mon[idx])\n",
    "        plt.xlim(0, 120)\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.ylabel('Sp/sec')\n",
    "        plt.text(1.25 * duration/br.ms, np.nanmax(s_mon[idx])/2., '%s SPL' % str(level*bh.dB));\n",
    "        ymin, ymax = plt.ylim()\n",
    "        if idx == 0:\n",
    "            plt.title('CF=%.0f Hz - Response to Tone at CF' % cf)\n",
    "\n",
    "        plt.figure(4)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(R_mon.times / br.ms, R_mon[idx])\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.text(1.25 * duration/br.ms, np.nanmax(R_mon[idx])/2., '%s SPL' % str(level*bh.dB));\n",
    "        plt.ylim(ymin, ymax)\n",
    "        if idx == 0:\n",
    "            plt.title('CF=%.0f Hz - Response to Tone at CF (with spikes and refractoriness)' % cf)\n",
    "        plt.plot(spike_mon.spiketimes[idx] / br.ms,\n",
    "             np.ones(len(spike_mon.spiketimes[idx])) * np.nanmax(R_mon[idx]), 'rx')\n",
    "\n",
    "\n",
    "ihc = bh.TanCarney(bh.MiddleEar(sound), cf, update_interval=1)\n",
    "ihc_mon = ihc.process()\n",
    "cochleogram(ihc_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dual resonance nonlinear filter\n",
    "\n",
    "# conversion to stape velocity (which are the units needed by the following centres)\n",
    "# sound = sound*0.00014\n",
    "\n",
    "#### Linear Pathway ####\n",
    "\n",
    "# bandpass filter (second order gammatone filter)\n",
    "center_frequencies_linear = 10**(-0.067+1.016*np.log10(center_frequencies))\n",
    "bandwidth_linear = 10**(0.037+0.785*np.log10(center_frequencies))\n",
    "order_linear = 3\n",
    "gammatone = bh.ApproximateGammatone(sound, center_frequencies_linear,\n",
    "                                    bandwidth_linear, order=order_linear)\n",
    "\n",
    "# linear gain\n",
    "g = 10**(4.2-0.48*np.log10(center_frequencies))\n",
    "func_gain = lambda x: g * x\n",
    "gain = bh.FunctionFilterbank(gammatone, func_gain)\n",
    "\n",
    "# low pass filter(cascade of 4 second order lowpass butterworth filters)\n",
    "cutoff_frequencies_linear = center_frequencies_linear\n",
    "order_lowpass_linear = 2\n",
    "lp_l = bh.LowPass(gain, cutoff_frequencies_linear)\n",
    "lowpass_linear = bh.Cascade(gain, lp_l, 4)\n",
    "\n",
    "#### Nonlinear Pathway ####\n",
    "\n",
    "# bandpass filter (third order gammatone filters)\n",
    "center_frequencies_nonlinear = center_frequencies\n",
    "bandwidth_nonlinear = 10**(-0.031+0.774*np.log10(center_frequencies))\n",
    "order_nonlinear = 3\n",
    "bandpass_nonlinear1 = bh.ApproximateGammatone(sound, center_frequencies_nonlinear,\n",
    "                                              bandwidth_nonlinear,\n",
    "                                              order=order_nonlinear)\n",
    "\n",
    "# compression (linear at low level, compress at high level)\n",
    "a = 10**(1.402+0.819*np.log10(center_frequencies))  # linear gain\n",
    "b = 10**(1.619-0.818*np.log10(center_frequencies))\n",
    "v = .2  # compression exponent\n",
    "func_compression = lambda x: np.sign(x) * np.minimum(a*np.abs(x), b*np.abs(x)**v)\n",
    "compression = bh.FunctionFilterbank(bandpass_nonlinear1, func_compression)\n",
    "\n",
    "# bandpass filter (third order gammatone filters)\n",
    "bandpass_nonlinear2 = bh.ApproximateGammatone(compression,\n",
    "                                              center_frequencies_nonlinear,\n",
    "                                              bandwidth_nonlinear,\n",
    "                                              order=order_nonlinear)\n",
    "\n",
    "# low pass filter\n",
    "cutoff_frequencies_nonlinear = center_frequencies_nonlinear\n",
    "order_lowpass_nonlinear = 2\n",
    "lp_nl = bh.LowPass(bandpass_nonlinear2, cutoff_frequencies_nonlinear)\n",
    "lowpass_nonlinear = bh.Cascade(bandpass_nonlinear2, lp_nl, 3)\n",
    "\n",
    "# adding the two pathways\n",
    "dnrl_filter = lowpass_linear + lowpass_nonlinear\n",
    "dnrl = dnrl_filter.process()\n",
    "\n",
    "cochleogram(dnrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DCGC; Compressive Gammachirp\n",
    "samplerate = sound.samplerate\n",
    "\n",
    "c1 = -2.96 # glide slope of the first filterbank\n",
    "b1 = 1.81  # factor determining the time constant of the first filterbank\n",
    "c2 = 2.2   # glide slope of the second filterbank\n",
    "b2 = 2.17  # factor determining the time constant of the second filterbank\n",
    "\n",
    "order_ERB = 4\n",
    "ERBrate = 21.4*np.log10(4.37*cf/1000+1)\n",
    "ERBwidth = 24.7*(4.37*cf/1000 + 1)\n",
    "ERBspace = np.mean(np.diff(ERBrate))\n",
    "\n",
    "# the filter coefficients are updated every update_interval (here in samples)\n",
    "update_interval = 1\n",
    "\n",
    "# bank of passive gammachirp filters. As the control path uses the same passive\n",
    "# filterbank than the signal path (but shifted in frequency)\n",
    "# this filterbank is used by both pathway.\n",
    "pGc = bh.LogGammachirp(sound, cf, b=b1, c=c1)\n",
    "\n",
    "fp1 = cf + c1*ERBwidth*b1/order_ERB #centre frequency of the signal path\n",
    "\n",
    "#### Control Path ####\n",
    "\n",
    "# the first filterbank in the control path consists of gammachirp filters\n",
    "# value of the shift in ERB frequencies of the control path with respect to the signal path\n",
    "lct_ERB = 1.5\n",
    "n_ch_shift = np.round(lct_ERB/ERBspace)  # value of the shift in channels\n",
    "# index of the channel of the control path taken from pGc\n",
    "indch1_control = np.minimum(np.maximum(1, np.arange(1, n_cf+1)+n_ch_shift), n_cf).astype(int)-1\n",
    "fp1_control = fp1[indch1_control]\n",
    "# the control path bank pass filter uses the channels of pGc indexed by indch1_control\n",
    "pGc_control = bh.RestructureFilterbank(pGc, indexmapping=indch1_control)\n",
    "\n",
    "# the second filterbank in the control path consists of fixed asymmetric compensation filters\n",
    "frat_control = 1.08\n",
    "fr2_control = frat_control*fp1_control\n",
    "asym_comp_control = bh.AsymmetricCompensation(pGc_control, fr2_control, b=b2, c=c2)\n",
    "\n",
    "# definition of the pole of the asymmetric comensation filters\n",
    "p0 = 2\n",
    "p1 = 1.7818*(1-0.0791*b2)*(1-0.1655*abs(c2))\n",
    "p2 = 0.5689*(1-0.1620*b2)*(1-0.0857*abs(c2))\n",
    "p3 = 0.2523*(1-0.0244*b2)*(1+0.0574*abs(c2))\n",
    "p4 = 1.0724\n",
    "\n",
    "# definition of the parameters used in the control path output levels computation\n",
    "# (see IEEE paper for details)\n",
    "decay_tcst = .5*br.ms\n",
    "order = 1.\n",
    "lev_weight = .5\n",
    "level_ref = 50.\n",
    "level_pwr1 = 1.5\n",
    "level_pwr2 = .5\n",
    "RMStoSPL = 30.\n",
    "frat0 = .2330\n",
    "frat1 = .005\n",
    "exp_deca_val = np.exp(-1/(decay_tcst*samplerate)*np.log(2))\n",
    "level_min = 10**(-RMStoSPL/20)\n",
    "\n",
    "# definition of the controller class. What is does it take the outputs of the\n",
    "# first and second fitlerbanks of the control filter as input, compute an overall\n",
    "# intensity level for each frequency channel. It then uses those level to update\n",
    "# the filter coefficient of its target, the asymmetric compensation filterbank of\n",
    "# the signal path.\n",
    "class CompensensationFilterUpdater(object):\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "        self.level1_prev = -100\n",
    "        self.level2_prev = -100\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        value1 = input[0][-1,:]\n",
    "        value2 = input[1][-1,:]\n",
    "        # the current level value is chosen as the max between the current\n",
    "        # output and the previous one decreased by a decay\n",
    "        level1 = np.maximum(np.maximum(value1, 0), self.level1_prev*exp_deca_val)\n",
    "        level2 = np.maximum(np.maximum(value2, 0), self.level2_prev*exp_deca_val)\n",
    "\n",
    "        self.level1_prev = level1  # the value is stored for the next iteration\n",
    "        self.level2_prev = level2\n",
    "        # the overall intensity is computed between the two filterbank outputs\n",
    "        level_total = (lev_weight*level_ref*(level1/level_ref)**level_pwr1+\n",
    "                  (1-lev_weight)*level_ref*(level2/level_ref)**level_pwr2)\n",
    "        # then it is converted in dB\n",
    "        level_dB = 20*np.log10(np.maximum(level_total, level_min))+RMStoSPL\n",
    "        # the frequency factor is calculated\n",
    "        frat = frat0 + frat1*level_dB\n",
    "        # the centre frequency of the asymmetric compensation filters are updated\n",
    "        fr2 = fp1*frat\n",
    "        coeffs = bh.asymmetric_compensation_coeffs(samplerate, fr2,\n",
    "                       self.target.filt_b, self.target.filt_a, b2, c2,\n",
    "                       p0, p1, p2, p3, p4)\n",
    "        self.target.filt_b, self.target.filt_a = coeffs\n",
    "\n",
    "#### Signal Path ####\n",
    "# the signal path consists of the passive gammachirp filterbank pGc previously\n",
    "# defined followed by a asymmetric compensation filterbank\n",
    "fr1 = fp1*frat0\n",
    "varyingfilter_signal_path = bh.AsymmetricCompensation(pGc, fr1, b=b2, c=c2)\n",
    "updater = CompensensationFilterUpdater(varyingfilter_signal_path)\n",
    "# the controler which takes the two filterbanks of the control path as inputs\n",
    "# and the varying filter of the signal path as target is instantiated\n",
    "control = bh.ControlFilterbank(varyingfilter_signal_path,\n",
    "                               [pGc_control, asym_comp_control],\n",
    "                               varyingfilter_signal_path, updater, update_interval)\n",
    "\n",
    "# run the simulation\n",
    "# Remember that the controler are at the end of the chain and the output of the\n",
    "# whole path comes from them\n",
    "signal = control.process()\n",
    "cochleogram(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zilany -- unfortunately doesn't work right now...\n",
    "from brian.hears.filtering.zilany import ZILANY\n",
    "\n",
    "zil = ZILANY(sound, cf, update_interval=1)\n",
    "zil_mon = zil.process()\n",
    "cochleogram(zil_mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hooking them up to Nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from brian.hears.filtering.tan_carney import ZhangSynapseRate\n",
    "from scipy.io.wavfile import read as readwav\n",
    "from scipy.signal import resample\n",
    "from nengo.utils.compat import range\n",
    "\n",
    "\n",
    "class FuncProcess(nengo.processes.Process):\n",
    "    \"\"\"Psych! Not a process, just a function.\n",
    "\n",
    "    Implemented so that we can use functions and\n",
    "    processes interchangeably without having to\n",
    "    write annoying conditionals.\n",
    "    \"\"\"\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    def make_step(self, size_in, size_out, dt, rng):\n",
    "        return self.fn\n",
    "\n",
    "\n",
    "class WavFile(nengo.processes.Process):\n",
    "    def __init__(self, path, at_end='loop'):\n",
    "        self.default_size_out = 1\n",
    "\n",
    "        self.path = path\n",
    "        # Possible at_end values:\n",
    "        #   loop: start again from the start\n",
    "        #   stop: output silence (0) after sound\n",
    "        assert at_end in ('loop', 'stop')\n",
    "        self.at_end = at_end\n",
    "\n",
    "    def make_step(self, size_in, size_out, dt, rng):\n",
    "        assert size_in == 0\n",
    "        assert size_out == 1\n",
    "\n",
    "        rate = 1. / dt\n",
    "\n",
    "        orig_rate, orig = readwav(self.path)\n",
    "        new_size = orig.size * (rate / orig_rate)\n",
    "        wave = resample(orig, new_size)\n",
    "        wave -= wave.mean()\n",
    "        wave *= 0.1  # arbitrary... should do this better\n",
    "        #wave *= 10\n",
    "\n",
    "        if self.at_end == 'loop':\n",
    "\n",
    "            def step_wavfileloop(t):\n",
    "                idx = int(t * rate) % wave.size\n",
    "                return wave[idx]\n",
    "            return step_wavfileloop\n",
    "\n",
    "        elif self.at_end == 'stop':\n",
    "\n",
    "            def step_wavfilestop(t):\n",
    "                idx = int(t * rate)\n",
    "                if idx > wave.size:\n",
    "                    return 0.\n",
    "                else:\n",
    "                    return wave[idx]\n",
    "            return step_wavfilestop\n",
    "\n",
    "\n",
    "class AuditoryFilterBank(nengo.processes.Process):\n",
    "    def __init__(self, freq, sound_process, filterbank, zhang_synapse=False, samplerate=None):\n",
    "        self.freq = freq\n",
    "        self.sound_process = sound_process\n",
    "        self.filterbank = filterbank\n",
    "        self.zhang_synapse = zhang_synapse\n",
    "        self.samplerate = samplerate\n",
    "\n",
    "    # IHC activity\n",
    "    @staticmethod\n",
    "    def bm2ihc(x):\n",
    "        \"\"\"Half wave rectify and compress it with a 1/3 power law.\"\"\"\n",
    "        return 3 * np.clip(x, 0, np.inf) ** (1. / 3.)\n",
    "\n",
    "    def make_step(self, size_in, size_out, dt, rng):\n",
    "        assert size_in == 0\n",
    "        assert size_out == self.freq.size\n",
    "\n",
    "        # If samplerate isn't specified, we'll assume dt\n",
    "        samplerate = 1. / dt if self.samplerate is None else self.samplerate\n",
    "        sound_dt = 1. / samplerate\n",
    "\n",
    "        # Set up the sound\n",
    "        step_f = self.sound_process.make_step(0, 1, sound_dt, rng)\n",
    "        ns = NengoSound(step_f, size_out, samplerate)\n",
    "        self.filterbank.source = ns\n",
    "\n",
    "        duration = int(dt / sound_dt)\n",
    "        self.filterbank.buffersize = duration\n",
    "        ihc = bh.FunctionFilterbank(self.filterbank, self.bm2ihc)        \n",
    "        # Fails if we don't do this...\n",
    "        ihc.cached_buffer_end = 0\n",
    "\n",
    "        if self.zhang_synapse:\n",
    "            syn = ZhangSynapseRate(ihc, self.freq)\n",
    "            s_mon = br.RecentStateMonitor(\n",
    "                syn, 's', record=True, clock=syn.clock, duration=dt * br.second)\n",
    "            net = br.Network(syn, s_mon)\n",
    "\n",
    "            def step_synapse(t):\n",
    "                net.run(dt * br.second)\n",
    "                return s_mon.values[-1]\n",
    "            return step_synapse\n",
    "        else:\n",
    "            def step_filterbank(t):\n",
    "                sound = ns.buffer_fetch_next(duration)\n",
    "                result = ihc.func(self.filterbank.buffer_apply(sound))\n",
    "                return result[-1]\n",
    "            return step_filterbank\n",
    "\n",
    "\n",
    "class NengoSound(bh.BaseSound):\n",
    "    def __init__(self, step_f, nchannels, samplerate):\n",
    "        self.step_f = step_f\n",
    "        self.nchannels = nchannels\n",
    "        self.samplerate = samplerate\n",
    "        self.t = 0.0\n",
    "        self.dt = 1. / self.samplerate\n",
    "\n",
    "    def buffer_init(self):\n",
    "        pass\n",
    "\n",
    "    def buffer_fetch(self, start, end):\n",
    "        return self.buffer_fetch_next(end - start)\n",
    "\n",
    "    def buffer_fetch_next(self, samples):\n",
    "        out = np.empty((samples, self.nchannels))\n",
    "        for i in range(samples):\n",
    "            self.t += self.dt\n",
    "            out[i] = self.step_f(self.t)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spnoise = WavFile('speech.wav')\n",
    "dt = 1./50000\n",
    "plt.plot(spnoise.trange(0.668, dt=dt), spnoise.run(0.668, dt=dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nengo auditory periphery model\n",
    "def periphery(freqs, noise, filterbank, neurons_per_freq=30,\n",
    "              zhang_synapse=False, fs=50000.):\n",
    "    # Inner hair cell activity\n",
    "    fb = AuditoryFilterBank(freqs, noise, br_filterbank,\n",
    "                            samplerate=fs, zhang_synapse=zhang_synapse)\n",
    "    ihc = nengo.Node(output=fb, size_out=freqs.size)\n",
    "\n",
    "    # Cochlear neurons projecting down auditory nerve\n",
    "    an = nengo.networks.EnsembleArray(neurons_per_freq, freqs.size,\n",
    "                                      neuron_nodes=True,  # For plotting raster\n",
    "                                      intercepts=nengo.dists.Uniform(0.4, 0.8),\n",
    "                                      encoders=nengo.dists.Choice([[1]]))\n",
    "    if zhang_synapse:\n",
    "        nengo.Connection(ihc, an.input, transform=0.1, synapse=None)\n",
    "    else:\n",
    "        nengo.Connection(ihc, an.input)\n",
    "    return ihc, an\n",
    "\n",
    "# Dummy sound for now; wnoise will be set during Nengo sim\n",
    "br_filterbank = bh.Gammatone(bh.Sound(np.zeros(0)), cf, b=1.019)\n",
    "wnoise = nengo.processes.WhiteNoise(nengo.dists.Gaussian(mean=0, std=0.01))\n",
    "tnoise = FuncProcess(lambda t: np.sin(2 * np.pi * t * 250))  # 250 Hz tone\n",
    "spnoise = WavFile('speech.wav')\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    ihc, an = periphery(cf, spnoise, br_filterbank, zhang_synapse=False)\n",
    "\n",
    "    # Probes\n",
    "    ihc_p = nengo.Probe(ihc, synapse=None)\n",
    "    an_in_p = nengo.Probe(an.input, synapse=None)\n",
    "    an_p = nengo.Probe(an.neuron_output, synapse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nengo.utils.matplotlib import rasterplot\n",
    "\n",
    "dt = 1. / cf.max()\n",
    "sim = nengo.Simulator(net, dt=dt*.5)\n",
    "sim.run(0.1)\n",
    "\n",
    "plt.figure()\n",
    "cochleogram(sim.data[ihc_p], sim.trange())\n",
    "plt.figure()\n",
    "cochleogram(sim.data[an_in_p], sim.trange())\n",
    "#plt.figure()\n",
    "#rasterplot(sim.trange(), sim.data[an_p])\n",
    "#plt.ylim(0, an.n_neurons * an.n_ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal processing with delay networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generic LTI stuff\n",
    "from scipy.linalg import solve_lyapunov\n",
    "from nengo.utils.filter_design import zpk2ss, tf2ss, ss2tf, cont2discrete\n",
    "\n",
    "\n",
    "class LTI(object):\n",
    "    def __init__(self, a, b, c, d):\n",
    "        self.a = np.array(a)\n",
    "        self.b = np.array(b)\n",
    "        self.c = np.array(c)\n",
    "        self.d = np.array(d)\n",
    "\n",
    "    @property\n",
    "    def abcd(self):\n",
    "        return (self.a, self.b, self.c, self.d)\n",
    "\n",
    "    @classmethod\n",
    "    def from_synapse(cls, synapse):\n",
    "        \"\"\"Instantiate class from a Nengo synapse.\"\"\"\n",
    "        if not hasattr(synapse, 'num') or not hasattr(synapse, 'den'):\n",
    "            raise ValueError(\"Must be a linear filter with 'num' and 'den'\")\n",
    "        return cls(tf2ss(synapse.num, synapse.den))\n",
    "\n",
    "    @classmethod\n",
    "    def from_tf(cls, num, den):\n",
    "        \"\"\"Instantiate class from a transfer function.\"\"\"\n",
    "        return cls(*tf2ss(num, den))\n",
    "\n",
    "    @classmethod\n",
    "    def from_zpk(cls, z, p, k):\n",
    "        \"\"\"Instantiate class from a zero-pole-gain representation.\"\"\"\n",
    "        return cls(zpk2ss(z, p, k))\n",
    "\n",
    "    def copy(self):\n",
    "        return LTI(*self.abcd)\n",
    "\n",
    "    def scale_to(self, radii=1.0):\n",
    "        \"\"\"Scales the system to give an effective radius of r to x.\"\"\"\n",
    "        r = np.asarray(radii, dtype=np.float64)\n",
    "        if r.ndim > 1:\n",
    "            raise ValueError(\"radii (%s) must be a 1-dim array or scalar\" % radii)\n",
    "        elif r.ndim == 0:\n",
    "            r = np.ones(len(self.a)) * r\n",
    "        self.a = self.a / r[:, None] * r\n",
    "        self.b /= r[:, None]\n",
    "        self.c *= r\n",
    "\n",
    "    def ab_norm(self):\n",
    "        \"\"\"Returns H2-norm of each component of x in the state-space.\n",
    "\n",
    "        Equivalently, this is the H2-norm of each component of (A, B, I, 0).\n",
    "        This gives the power of each component of x in response to white-noise\n",
    "        input with uniform power.\n",
    "\n",
    "        Useful for setting the radius of an ensemble array with continuous\n",
    "        dynamics (A, B)\n",
    "        \"\"\"\n",
    "        p = solve_lyapunov(self.a, -np.dot(self.b, self.b.T))  # AP + PA^H = Q\n",
    "        assert np.allclose(np.dot(self.a, p) + np.dot(p, self.a.T) + np.dot(self.b, self.b.T), 0)\n",
    "        c = np.eye(len(self.a))\n",
    "        h2norm = np.dot(c, np.dot(p, c.T))\n",
    "        # The H2 norm of (A, B, C) is sqrt(tr(CXC^T)), so if we want the norm of\n",
    "        # each component in the state-space representation, we evaluate this for\n",
    "        # each elementary vector C separately, which is equivalent to just picking\n",
    "        # out the diagonals\n",
    "        return np.sqrt(h2norm[np.diag_indices(len(h2norm))])\n",
    "\n",
    "    def to_sim(self, synapse, dt=0, copy=True):\n",
    "        \"\"\"Maps a state-space LTI to the synaptic dynamics on A and B.\"\"\"\n",
    "        if not isinstance(synapse, nengo.Lowpass):\n",
    "            raise TypeError(\"synapse (%s) must be Lowpass\" % (synapse,))\n",
    "        if dt == 0:\n",
    "            a = synapse.tau * self.a + np.eye(len(self.a))\n",
    "            b = synapse.tau * self.b\n",
    "        else:\n",
    "            a, b, c, d, _ = cont2discrete(self.abcd, dt=dt)\n",
    "            aa = np.exp(-dt / synapse.tau)\n",
    "            a = 1. / (1 - aa) * (a - aa * np.eye(len(a)))\n",
    "            b = 1. / (1 - aa) * b\n",
    "        if copy:\n",
    "            return LTI(a, b, c, d)\n",
    "        else:\n",
    "            self.a, self.b, self.c, self.d = a, b, c, d\n",
    "\n",
    "\n",
    "def exp_delay(p, q, c=1.0):\n",
    "    \"\"\"Returns F = p/q such that F(s) = e^(-sc).\"\"\"\n",
    "    # This leads to the same matrices used by the Delay LTISystem, except\n",
    "    # this is numeric and the latter is the symbolic solution\n",
    "    from scipy.misc import pade, factorial\n",
    "    i = np.arange(1, p+q+1)\n",
    "    taylor = np.append([1.0], (-c)**i / factorial(i))\n",
    "    return pade(taylor, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nengo.utils.compat import is_number\n",
    "\n",
    "# LTI in Nengo\n",
    "def lti_net(n_neurons, lti, synapse=nengo.Lowpass(0.05),\n",
    "            controlled=False, dt=0.001, radii=None, radius=1.0):\n",
    "    lti = lti.copy()\n",
    "    if radii is None:\n",
    "        radii = lti.ab_norm()\n",
    "    radii *= radius\n",
    "    lti.scale_to(radii)  # Probably should require this outside of this function\n",
    "    lti.to_sim(synapse, dt, copy=False)\n",
    "\n",
    "    size_in = lti.b.shape[1]\n",
    "    size_state = lti.a.shape[0]\n",
    "    size_out = lti.c.shape[0]\n",
    "\n",
    "    a, b, c, d = lti.abcd\n",
    "\n",
    "    inp = nengo.Node(size_in=size_in, label=\"input\")\n",
    "    out = nengo.Node(size_in=size_out, label=\"output\")\n",
    "    if controlled:\n",
    "        x = Product(n_neurons, size_state)\n",
    "        x_in = x.A\n",
    "    else:\n",
    "        x = nengo.networks.EnsembleArray(n_neurons, size_state)\n",
    "        x_in = x.input\n",
    "    x_out = x.output\n",
    "    \n",
    "    nengo.Connection(x_out, x_in, transform=a, synapse=synapse)\n",
    "    nengo.Connection(inp, x_in, transform=b, synapse=synapse)\n",
    "    nengo.Connection(x_out, out, transform=c, synapse=None)\n",
    "    nengo.Connection(inp, out, transform=d, synapse=None)\n",
    "\n",
    "    return inp, out\n",
    "\n",
    "\n",
    "class Highpass(nengo.LinearFilter):\n",
    "    \"\"\"Differentiated lowpass, raised to a given power.\"\"\"\n",
    "    def __init__(self, tau, order=1):\n",
    "        if order < 1 or not is_number(order):\n",
    "            raise ValueError(\"order (%s) must be integer >= 1\" % order)\n",
    "        num, den = [np.poly1d([tau, 0]), np.poly1d([tau, 1])]\n",
    "        super(Highpass, self).__init__(num=num**order, den=den**order)\n",
    "\n",
    "\n",
    "# Differentiator\n",
    "def deconv_net(n_neurons, tf, delay, degree=4, **lti_kwargs):\n",
    "    \"\"\"Approximate the inverse of a given transfer function using a delay.\"\"\"\n",
    "    num, den = [np.poly1d(tf[0]), np.poly1d(tf[1])]\n",
    "    order = len(den) - len(num)\n",
    "    # t.f. can be non-causal as long as the delay order accounts for it\n",
    "    if order >= degree:\n",
    "        raise ValueError(\"order (%s) must be < degree (%s)\"\n",
    "                         % (order, degree))\n",
    "    # given the tf (1, 1), this is equivalent to Delay,\n",
    "    # however this uses exp_delay rather than the symbolic solution for\n",
    "    # the state-space representation\n",
    "    edp, edq = exp_delay(degree - order, degree, delay)\n",
    "    p, q = np.polymul(edp, den), np.polymul(edq, num)\n",
    "    lti = LTI.from_tf(p, q)\n",
    "    inp, out = lti_net(n_neurons, lti, **lti_kwargs)\n",
    "    return inp, out, degree\n",
    "\n",
    "\n",
    "def diff_net(n_neurons, tau, delay, **deconv_kwargs):\n",
    "    \"\"\"Output a signal that is a derivative of the input.\"\"\"\n",
    "    return deconv_net(n_neurons, ([1], [tau, 0]), delay, **deconv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tau_highpass = 0.05\n",
    "br_filterbank = bh.Gammatone(bh.Sound(np.zeros(0)), cf, b=1.019)\n",
    "wnoise = nengo.processes.WhiteNoise(nengo.dists.Gaussian(mean=0, std=0.01))\n",
    "tnoise = FuncProcess(lambda t: np.sin(2 * np.pi * t * 250))  # 250 Hz tone\n",
    "spnoise = WavFile('speech.wav')\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    # Input is auditory periphery layer\n",
    "    ihc, an = periphery(cf, spnoise, br_filterbank, zhang_synapse=False)\n",
    "\n",
    "    # Try 10 ms and 30 ms derivative\n",
    "    shortderiv = nengo.Node(None, size_in=cf.size)\n",
    "    for i, freq in enumerate(cf):\n",
    "        diff_in, diff_out, _ = diff_net(50, tau=tau_highpass, delay=0.008, radius=0.1)\n",
    "        nengo.Connection(an.output[i], diff_in)\n",
    "        nengo.Connection(diff_out, shortderiv[i], synapse=tau_highpass)\n",
    "\n",
    "    longderiv = nengo.Node(None, size_in=cf.size)\n",
    "    for i, freq in enumerate(cf):\n",
    "        diff_in, diff_out, _ = diff_net(50, tau=tau_highpass, delay=0.02, radius=0.1)\n",
    "        nengo.Connection(an.output[i], diff_in)\n",
    "        nengo.Connection(diff_out, longderiv[i], synapse=tau_highpass)\n",
    "\n",
    "    # Probes\n",
    "    ihc_p = nengo.Probe(ihc, synapse=None)\n",
    "    an_p = nengo.Probe(an.output, synapse=0.01)\n",
    "    short_p = nengo.Probe(shortderiv, synapse=0.01)\n",
    "    long_p = nengo.Probe(longderiv, synapse=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 1. / cf.max()\n",
    "sim = nengo.Simulator(net, dt=dt*.5)\n",
    "sim.run(0.667)\n",
    "\n",
    "plt.figure()\n",
    "cochleogram(sim.data[ihc_p], sim.trange())\n",
    "plt.figure()\n",
    "cochleogram(sim.data[an_p], sim.trange())\n",
    "plt.figure()\n",
    "cochleogram(sim.data[short_p], sim.trange())\n",
    "plt.figure()\n",
    "cochleogram(sim.data[long_p], sim.trange())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum(ens.n_neurons for ens in net.all_ensembles))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
