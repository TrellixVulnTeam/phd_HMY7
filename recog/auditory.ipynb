{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from JSAnimation import IPython_display\n",
    "from skspeech.synthesis import kroger as kr\n",
    "\n",
    "import nengo\n",
    "import nengo.utils.numpy as npext\n",
    "import nengo_gui.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some plotting niceties\n",
    "plt.rc('figure', figsize=(10, 8))\n",
    "\n",
    "def shiftedcmap(cmap, start=0, midpoint=0.5, stop=1.0, name='shiftedcmap'):\n",
    "    \"\"\"Offset the 'center' of a colormap.\n",
    "\n",
    "    Useful for data with a negative min and positive max and you\n",
    "    want the middle of the colormap's dynamic range to be at zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmap : The matplotlib colormap to be altered\n",
    "    start : Offset from lowest point in the colormap's range.\n",
    "            Defaults to 0.0 (no lower ofset). Should be between\n",
    "            0.0 and `midpoint`.\n",
    "    midpoint : The new center of the colormap. Defaults to \n",
    "               0.5 (no shift). Should be between 0.0 and 1.0. In\n",
    "               general, this should be  1 - vmax/(vmax + abs(vmin))\n",
    "               For example if your data range from -15.0 to +5.0 and\n",
    "               you want the center of the colormap at 0.0, `midpoint`\n",
    "              should be set to  1 - 5/(5 + 15)) or 0.75\n",
    "    stop : Offset from highets point in the colormap's range.\n",
    "           Defaults to 1.0 (no upper ofset). Should be between\n",
    "           `midpoint` and 1.0.\n",
    "\n",
    "    From http://stackoverflow.com/questions/7404116/defining-the-midpoint-of-a-colormap-in-matplotlib\n",
    "    \"\"\"\n",
    "    cdict = {\n",
    "        'red': [],\n",
    "        'green': [],\n",
    "        'blue': [],\n",
    "        'alpha': []\n",
    "    }\n",
    "\n",
    "    # regular index to compute the colors\n",
    "    reg_index = np.linspace(start, stop, 257)\n",
    "\n",
    "    # shifted index to match the data\n",
    "    shift_index = np.hstack([\n",
    "        np.linspace(0.0, midpoint, 128, endpoint=False), \n",
    "        np.linspace(midpoint, 1.0, 129, endpoint=True)\n",
    "    ])\n",
    "\n",
    "    for ri, si in zip(reg_index, shift_index):\n",
    "        r, g, b, a = cmap(ri)\n",
    "        cdict['red'].append((si, r, r))\n",
    "        cdict['green'].append((si, g, g))\n",
    "        cdict['blue'].append((si, b, b))\n",
    "        cdict['alpha'].append((si, a, a))\n",
    "\n",
    "    newcmap = matplotlib.colors.LinearSegmentedColormap(name, cdict)\n",
    "    plt.register_cmap(cmap=newcmap)\n",
    "\n",
    "    return newcmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditory periphery\n",
    "\n",
    "Making heavy use of [Brian hears](http://www.briansimulator.org/docs/hears.html),\n",
    "but should also investigate other periphery models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brian filter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import brian_no_units  # For speed\n",
    "import brian as br\n",
    "import brian.hears as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def whitenoise_sound():\n",
    "    sound = bh.whitenoise(100*br.ms).ramp()\n",
    "    sound.level = 50*bh.dB\n",
    "    sound.samplerate = 50*br.kHz\n",
    "    return sound\n",
    "\n",
    "def tone_sound():\n",
    "    sound = bh.tone(500*br.Hz, 100*br.ms).ramp()\n",
    "    sound.level = 50*bh.dB\n",
    "    sound.samplerate = 50*br.kHz\n",
    "    return sound\n",
    "\n",
    "def cochleogram(gt_mon, time=None):\n",
    "    cmap = plt.cm.RdBu\n",
    "    if gt_mon.min() >= 0.0:\n",
    "        cmap = plt.cm.Blues\n",
    "    elif not np.allclose(gt_mon.max() + gt_mon.min(), 0, atol=1e-5):\n",
    "        midpoint = np.abs(gt_mon.min()) / (gt_mon.max() - gt_mon.min())\n",
    "        cmap = shiftedcmap(cmap, midpoint=midpoint)\n",
    "\n",
    "    duration = time[-1] if time is not None else sound.duration / br.ms\n",
    "    plt.imshow(gt_mon.T, aspect='auto', origin='lower left', cmap=cmap,\n",
    "               extent=(0, duration, cf[0], cf[-1]))\n",
    "    plt.yscale('log')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.colorbar()\n",
    "\n",
    "sound = whitenoise_sound()\n",
    "# sound = tone_sound()\n",
    "n_cf = n_center_frequencies = 200\n",
    "cf = center_frequencies = bh.erbspace(100*br.Hz, 1000*br.Hz, n_center_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gammatone\n",
    "from brian.hears.filtering.tan_carney import ZhangSynapseRate\n",
    "\n",
    "b1 = 1.019  # factor determining the time constant of the filters\n",
    "\n",
    "# Apply middle ear filter?\n",
    "if False:\n",
    "    gammatone = bh.Gammatone(bh.MiddleEar(sound), center_frequencies, b=b1)\n",
    "else:\n",
    "    gammatone = bh.Gammatone(sound, center_frequencies, b=b1)\n",
    "\n",
    "gt_mon = gammatone.process()\n",
    "cochleogram(gt_mon)\n",
    "plt.title('Cochleogram')\n",
    "\n",
    "# half wave rectify and compress it with a 1/3 power law\n",
    "plt.figure()\n",
    "ihc = bh.FunctionFilterbank(gammatone, lambda x: 3 * np.clip(x, 0, np.inf) ** (1. / 3.))\n",
    "cochleogram(ihc.process())\n",
    "plt.title('IHC activity')\n",
    "\n",
    "# Get AN fiber rates\n",
    "plt.figure()\n",
    "syn = ZhangSynapseRate(ihc, cf)\n",
    "s_mon = br.StateMonitor(syn, 's', record=True, clock=syn.clock)\n",
    "net = br.Network(syn, s_mon)\n",
    "net.run(sound.duration)\n",
    "cochleogram(s_mon.values.T)\n",
    "plt.title('AN spike rates')\n",
    "\n",
    "# Let's see spikes now...\n",
    "plt.figure()\n",
    "syn = bh.ZhangSynapse(ihc, cf)\n",
    "sp_mon = br.SpikeMonitor(syn)\n",
    "net = br.Network(syn, sp_mon)\n",
    "net.run(sound.duration)\n",
    "br.raster_plot(sp_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Approximate Gammatone\n",
    "\n",
    "# bandwidth of the filters (different in each channel)\n",
    "bw = 10**(0.037+0.785*np.log10(center_frequencies))\n",
    "gammatone = bh.ApproximateGammatone(sound, center_frequencies, bw, order=3)\n",
    "gt_mon = gammatone.process()\n",
    "cochleogram(gt_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log Gammachirp\n",
    "\n",
    "c1 = -2.96 # glide slope\n",
    "b1 = 1.81  # factor determining the time constant of the filters\n",
    "gamma_chirp = bh.LogGammachirp(sound, cf, c=c1, b=b1)\n",
    "gamma_chirp_mon = gamma_chirp.process()\n",
    "cochleogram(gamma_chirp_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Gammachirp\n",
    "\n",
    "c = 0.0 # glide slope\n",
    "time_constant = np.linspace(3, 0.3, n_center_frequencies) * br.ms\n",
    "gamma_chirp = bh.LinearGammachirp(sound, center_frequencies, time_constant, c)\n",
    "gamma_chirp_mon = gamma_chirp.process()\n",
    "cochleogram(gamma_chirp_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tan & Carney\n",
    "reproduce_paper_figs = False\n",
    "if reproduce_paper_figs:\n",
    "    bh.set_default_samplerate(50*br.kHz)\n",
    "    sample_length = 1 / bh.get_samplerate(None)\n",
    "    cf = 1000 * br.Hz\n",
    "\n",
    "    print 'Testing click response'\n",
    "    duration = 25 * br.ms\n",
    "    levels = [40, 60, 80, 100, 120]\n",
    "    # a click of two samples\n",
    "    tones = bh.Sound([bh.Sound.sequence([bh.click(sample_length*2, peak=level*bh.dB),\n",
    "                                         bh.silence(duration=duration - sample_length)])\n",
    "                      for level in levels])\n",
    "    ihc = bh.TanCarney(bh.MiddleEar(tones), [cf] * len(levels), update_interval=1)\n",
    "    syn = bh.ZhangSynapse(ihc, cf)\n",
    "    s_mon = br.StateMonitor(syn, 's', record=True, clock=syn.clock)\n",
    "    R_mon = br.StateMonitor(syn, 'R', record=True, clock=syn.clock)\n",
    "    spike_mon = br.SpikeMonitor(syn)\n",
    "    net = br.Network(syn, s_mon, R_mon, spike_mon)\n",
    "    net.run(duration * 1.5)\n",
    "\n",
    "    for idx, level in enumerate(levels):\n",
    "        plt.figure(1)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(s_mon.times / br.ms, s_mon[idx])\n",
    "        plt.xlim(0, 25)\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.ylabel('Sp/sec')\n",
    "        plt.text(15, np.nanmax(s_mon[idx])/2., 'Peak SPL=%s SPL' % str(level*bh.dB));\n",
    "        ymin, ymax = plt.ylim()\n",
    "        if idx == 0:\n",
    "            plt.title('Click responses')\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(R_mon.times / br.ms, R_mon[idx])\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.text(15, np.nanmax(s_mon[idx])/2., 'Peak SPL=%s SPL' % str(level*bh.dB));\n",
    "        plt.ylim(ymin, ymax)\n",
    "        if idx == 0:\n",
    "            plt.title('Click responses (with spikes and refractoriness)')\n",
    "        plt.plot(spike_mon.spiketimes[idx] / br.ms,\n",
    "             np.ones(len(spike_mon.spiketimes[idx])) * np.nanmax(R_mon[idx]), 'rx')\n",
    "\n",
    "    print 'Testing tone response'\n",
    "    br.reinit_default_clock()\n",
    "    duration = 60*br.ms\n",
    "    levels = [0, 20, 40, 60, 80]\n",
    "    tones = bh.Sound([bh.Sound.sequence([bh.tone(cf, duration).atlevel(level*bh.dB).ramp(when='both',\n",
    "                                                                                         duration=10*br.ms,\n",
    "                                                                                         inplace=False),\n",
    "                                         bh.silence(duration=duration/2)])\n",
    "                      for level in levels])\n",
    "    ihc = bh.TanCarney(bh.MiddleEar(tones), [cf] * len(levels), update_interval=1)\n",
    "    syn = bh.ZhangSynapse(ihc, cf)\n",
    "    s_mon = br.StateMonitor(syn, 's', record=True, clock=syn.clock)\n",
    "    R_mon = br.StateMonitor(syn, 'R', record=True, clock=syn.clock)\n",
    "    spike_mon = br.SpikeMonitor(syn)\n",
    "    net = br.Network(syn, s_mon, R_mon, spike_mon)\n",
    "    net.run(duration * 1.5)\n",
    "    for idx, level in enumerate(levels):\n",
    "        plt.figure(3)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(s_mon.times / br.ms, s_mon[idx])\n",
    "        plt.xlim(0, 120)\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.ylabel('Sp/sec')\n",
    "        plt.text(1.25 * duration/br.ms, np.nanmax(s_mon[idx])/2., '%s SPL' % str(level*bh.dB));\n",
    "        ymin, ymax = plt.ylim()\n",
    "        if idx == 0:\n",
    "            plt.title('CF=%.0f Hz - Response to Tone at CF' % cf)\n",
    "\n",
    "        plt.figure(4)\n",
    "        plt.subplot(len(levels), 1, idx + 1)\n",
    "        plt.plot(R_mon.times / br.ms, R_mon[idx])\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.xlabel('Time (msec)')\n",
    "        plt.text(1.25 * duration/br.ms, np.nanmax(R_mon[idx])/2., '%s SPL' % str(level*bh.dB));\n",
    "        plt.ylim(ymin, ymax)\n",
    "        if idx == 0:\n",
    "            plt.title('CF=%.0f Hz - Response to Tone at CF (with spikes and refractoriness)' % cf)\n",
    "        plt.plot(spike_mon.spiketimes[idx] / br.ms,\n",
    "             np.ones(len(spike_mon.spiketimes[idx])) * np.nanmax(R_mon[idx]), 'rx')\n",
    "\n",
    "\n",
    "ihc = bh.TanCarney(bh.MiddleEar(sound), cf, update_interval=1)\n",
    "ihc_mon = ihc.process()\n",
    "cochleogram(ihc_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dual resonance nonlinear filter\n",
    "\n",
    "# conversion to stape velocity (which are the units needed by the following centres)\n",
    "# sound = sound*0.00014\n",
    "\n",
    "#### Linear Pathway ####\n",
    "\n",
    "# bandpass filter (second order gammatone filter)\n",
    "center_frequencies_linear = 10**(-0.067+1.016*np.log10(center_frequencies))\n",
    "bandwidth_linear = 10**(0.037+0.785*np.log10(center_frequencies))\n",
    "order_linear = 3\n",
    "gammatone = bh.ApproximateGammatone(sound, center_frequencies_linear,\n",
    "                                    bandwidth_linear, order=order_linear)\n",
    "\n",
    "# linear gain\n",
    "g = 10**(4.2-0.48*np.log10(center_frequencies))\n",
    "func_gain = lambda x: g * x\n",
    "gain = bh.FunctionFilterbank(gammatone, func_gain)\n",
    "\n",
    "# low pass filter(cascade of 4 second order lowpass butterworth filters)\n",
    "cutoff_frequencies_linear = center_frequencies_linear\n",
    "order_lowpass_linear = 2\n",
    "lp_l = bh.LowPass(gain, cutoff_frequencies_linear)\n",
    "lowpass_linear = bh.Cascade(gain, lp_l, 4)\n",
    "\n",
    "#### Nonlinear Pathway ####\n",
    "\n",
    "# bandpass filter (third order gammatone filters)\n",
    "center_frequencies_nonlinear = center_frequencies\n",
    "bandwidth_nonlinear = 10**(-0.031+0.774*np.log10(center_frequencies))\n",
    "order_nonlinear = 3\n",
    "bandpass_nonlinear1 = bh.ApproximateGammatone(sound, center_frequencies_nonlinear,\n",
    "                                              bandwidth_nonlinear,\n",
    "                                              order=order_nonlinear)\n",
    "\n",
    "# compression (linear at low level, compress at high level)\n",
    "a = 10**(1.402+0.819*np.log10(center_frequencies))  # linear gain\n",
    "b = 10**(1.619-0.818*np.log10(center_frequencies))\n",
    "v = .2  # compression exponent\n",
    "func_compression = lambda x: np.sign(x) * np.minimum(a*np.abs(x), b*np.abs(x)**v)\n",
    "compression = bh.FunctionFilterbank(bandpass_nonlinear1, func_compression)\n",
    "\n",
    "# bandpass filter (third order gammatone filters)\n",
    "bandpass_nonlinear2 = bh.ApproximateGammatone(compression,\n",
    "                                              center_frequencies_nonlinear,\n",
    "                                              bandwidth_nonlinear,\n",
    "                                              order=order_nonlinear)\n",
    "\n",
    "# low pass filter\n",
    "cutoff_frequencies_nonlinear = center_frequencies_nonlinear\n",
    "order_lowpass_nonlinear = 2\n",
    "lp_nl = bh.LowPass(bandpass_nonlinear2, cutoff_frequencies_nonlinear)\n",
    "lowpass_nonlinear = bh.Cascade(bandpass_nonlinear2, lp_nl, 3)\n",
    "\n",
    "# adding the two pathways\n",
    "dnrl_filter = lowpass_linear + lowpass_nonlinear\n",
    "dnrl = dnrl_filter.process()\n",
    "\n",
    "cochleogram(dnrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DCGC; Compressive Gammachirp\n",
    "samplerate = sound.samplerate\n",
    "\n",
    "c1 = -2.96 # glide slope of the first filterbank\n",
    "b1 = 1.81  # factor determining the time constant of the first filterbank\n",
    "c2 = 2.2   # glide slope of the second filterbank\n",
    "b2 = 2.17  # factor determining the time constant of the second filterbank\n",
    "\n",
    "order_ERB = 4\n",
    "ERBrate = 21.4*np.log10(4.37*cf/1000+1)\n",
    "ERBwidth = 24.7*(4.37*cf/1000 + 1)\n",
    "ERBspace = np.mean(np.diff(ERBrate))\n",
    "\n",
    "# the filter coefficients are updated every update_interval (here in samples)\n",
    "update_interval = 1\n",
    "\n",
    "# bank of passive gammachirp filters. As the control path uses the same passive\n",
    "# filterbank than the signal path (but shifted in frequency)\n",
    "# this filterbank is used by both pathway.\n",
    "pGc = bh.LogGammachirp(sound, cf, b=b1, c=c1)\n",
    "\n",
    "fp1 = cf + c1*ERBwidth*b1/order_ERB #centre frequency of the signal path\n",
    "\n",
    "#### Control Path ####\n",
    "\n",
    "# the first filterbank in the control path consists of gammachirp filters\n",
    "# value of the shift in ERB frequencies of the control path with respect to the signal path\n",
    "lct_ERB = 1.5\n",
    "n_ch_shift = np.round(lct_ERB/ERBspace)  # value of the shift in channels\n",
    "# index of the channel of the control path taken from pGc\n",
    "indch1_control = np.minimum(np.maximum(1, np.arange(1, n_cf+1)+n_ch_shift), n_cf).astype(int)-1\n",
    "fp1_control = fp1[indch1_control]\n",
    "# the control path bank pass filter uses the channels of pGc indexed by indch1_control\n",
    "pGc_control = bh.RestructureFilterbank(pGc, indexmapping=indch1_control)\n",
    "\n",
    "# the second filterbank in the control path consists of fixed asymmetric compensation filters\n",
    "frat_control = 1.08\n",
    "fr2_control = frat_control*fp1_control\n",
    "asym_comp_control = bh.AsymmetricCompensation(pGc_control, fr2_control, b=b2, c=c2)\n",
    "\n",
    "# definition of the pole of the asymmetric comensation filters\n",
    "p0 = 2\n",
    "p1 = 1.7818*(1-0.0791*b2)*(1-0.1655*abs(c2))\n",
    "p2 = 0.5689*(1-0.1620*b2)*(1-0.0857*abs(c2))\n",
    "p3 = 0.2523*(1-0.0244*b2)*(1+0.0574*abs(c2))\n",
    "p4 = 1.0724\n",
    "\n",
    "# definition of the parameters used in the control path output levels computation\n",
    "# (see IEEE paper for details)\n",
    "decay_tcst = .5*br.ms\n",
    "order = 1.\n",
    "lev_weight = .5\n",
    "level_ref = 50.\n",
    "level_pwr1 = 1.5\n",
    "level_pwr2 = .5\n",
    "RMStoSPL = 30.\n",
    "frat0 = .2330\n",
    "frat1 = .005\n",
    "exp_deca_val = np.exp(-1/(decay_tcst*samplerate)*np.log(2))\n",
    "level_min = 10**(-RMStoSPL/20)\n",
    "\n",
    "# definition of the controller class. What is does it take the outputs of the\n",
    "# first and second fitlerbanks of the control filter as input, compute an overall\n",
    "# intensity level for each frequency channel. It then uses those level to update\n",
    "# the filter coefficient of its target, the asymmetric compensation filterbank of\n",
    "# the signal path.\n",
    "class CompensensationFilterUpdater(object):\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "        self.level1_prev = -100\n",
    "        self.level2_prev = -100\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        value1 = input[0][-1,:]\n",
    "        value2 = input[1][-1,:]\n",
    "        # the current level value is chosen as the max between the current\n",
    "        # output and the previous one decreased by a decay\n",
    "        level1 = np.maximum(np.maximum(value1, 0), self.level1_prev*exp_deca_val)\n",
    "        level2 = np.maximum(np.maximum(value2, 0), self.level2_prev*exp_deca_val)\n",
    "\n",
    "        self.level1_prev = level1  # the value is stored for the next iteration\n",
    "        self.level2_prev = level2\n",
    "        # the overall intensity is computed between the two filterbank outputs\n",
    "        level_total = (lev_weight*level_ref*(level1/level_ref)**level_pwr1+\n",
    "                  (1-lev_weight)*level_ref*(level2/level_ref)**level_pwr2)\n",
    "        # then it is converted in dB\n",
    "        level_dB = 20*np.log10(np.maximum(level_total, level_min))+RMStoSPL\n",
    "        # the frequency factor is calculated\n",
    "        frat = frat0 + frat1*level_dB\n",
    "        # the centre frequency of the asymmetric compensation filters are updated\n",
    "        fr2 = fp1*frat\n",
    "        coeffs = bh.asymmetric_compensation_coeffs(samplerate, fr2,\n",
    "                       self.target.filt_b, self.target.filt_a, b2, c2,\n",
    "                       p0, p1, p2, p3, p4)\n",
    "        self.target.filt_b, self.target.filt_a = coeffs\n",
    "\n",
    "#### Signal Path ####\n",
    "# the signal path consists of the passive gammachirp filterbank pGc previously\n",
    "# defined followed by a asymmetric compensation filterbank\n",
    "fr1 = fp1*frat0\n",
    "varyingfilter_signal_path = bh.AsymmetricCompensation(pGc, fr1, b=b2, c=c2)\n",
    "updater = CompensensationFilterUpdater(varyingfilter_signal_path)\n",
    "# the controler which takes the two filterbanks of the control path as inputs\n",
    "# and the varying filter of the signal path as target is instantiated\n",
    "control = bh.ControlFilterbank(varyingfilter_signal_path,\n",
    "                               [pGc_control, asym_comp_control],\n",
    "                               varyingfilter_signal_path, updater, update_interval)\n",
    "\n",
    "# run the simulation\n",
    "# Remember that the controler are at the end of the chain and the output of the\n",
    "# whole path comes from them\n",
    "signal = control.process()\n",
    "cochleogram(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zilany -- unfortunately doesn't work right now...\n",
    "from brian.hears.filtering.zilany import ZILANY\n",
    "\n",
    "zil = ZILANY(sound, cf, update_interval=1)\n",
    "zil_mon = zil.process()\n",
    "cochleogram(zil_mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hooking them up to Nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AuditoryFilterBank(nengo.processes.Process):\n",
    "    def __init__(self, freq, sound_process, filterbank_cls, fb_kwargs={}):\n",
    "        assert 'samplerate' not in fb_kwargs\n",
    "        self.freq = freq\n",
    "        self.sound_process = sound_process\n",
    "        self.filterbank_cls = filterbank_cls\n",
    "        self.fb_kwargs = fb_kwargs\n",
    "\n",
    "    def make_step(self, size_in, size_out, dt, rng):\n",
    "        assert size_in == 0\n",
    "        assert size_out == self.freq.size\n",
    "\n",
    "        # Assuming dt is correct\n",
    "        samplerate = 1. / dt\n",
    "        step_f = self.sound_process.make_step(0, 1, dt, rng)\n",
    "        ns = NengoSound(step_f, size_out, samplerate)\n",
    "        fb = self.filterbank_cls(ns, self.freq, **self.fb_kwargs)\n",
    "        fb.buffersize = 1\n",
    "\n",
    "        def step_filterbank(t):\n",
    "            return fb.buffer_apply(ns.buffer_fetch_next(1))\n",
    "        return step_filterbank\n",
    "\n",
    "\n",
    "class NengoSound(bh.BaseSound):\n",
    "    def __init__(self, step_f, nchannels, samplerate):\n",
    "        self.step_f = step_f\n",
    "        self.nchannels = nchannels\n",
    "        self.samplerate = samplerate\n",
    "        self.t = 0.0\n",
    "        self.dt = 1. / self.samplerate\n",
    "\n",
    "    def buffer_init(self):\n",
    "        pass\n",
    "\n",
    "    def buffer_fetch(self, start, end):\n",
    "        assert end - start == 1\n",
    "        return self.buffer_fetch_next(end - start)\n",
    "\n",
    "    def buffer_fetch_next(self, samples):\n",
    "        assert samples == 1\n",
    "        self.t += self.dt\n",
    "        return np.tile(self.step_f(self.t), (1, self.nchannels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple Nengo model that does the filtering during a sim\n",
    "fs = 50000.\n",
    "dt = 1. / fs\n",
    "freq = cf\n",
    "\n",
    "# Brian stuff\n",
    "\n",
    "# Gammatone\n",
    "br_filterbank = bh.Gammatone\n",
    "fb_args = {'b': 1.019}\n",
    "\n",
    "# Approximate Gammatone\n",
    "# br_filterbank = bh.ApproximateGammatone\n",
    "# fb_args = {'bandwidth': 10 ** (0.037 + 0.785 * np.log10(cf)),\n",
    "#            'order': 3}\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    # Incoming audio signal\n",
    "    wnoise = nengo.processes.WhiteNoise(nengo.dists.Gaussian(mean=0, std=0.01))\n",
    "\n",
    "    # Get basilar membrane deflection with Brian filter\n",
    "    fb = AuditoryFilterBank(freq, wnoise, br_filterbank, fb_args)\n",
    "    bm = nengo.Node(output=fb, size_out=freq.size)\n",
    "\n",
    "    # Cochlear neurons project down auditory nerve\n",
    "    an = nengo.networks.EnsembleArray(1, cf.size,\n",
    "                                      neuron_nodes=True,\n",
    "                                      intercepts=nengo.dists.Choice([0.2]),\n",
    "                                      encoders=nengo.dists.Choice([[1]]))\n",
    "\n",
    "    # Half wave rectify and compress it with a 1/3 power law\n",
    "    nengo.Connection(bm, an.input, function=lambda x: 3 * np.clip(x, 0, np.inf) ** (1. / 3.))\n",
    "\n",
    "    # TODO: Insert Zhang synapse in here!\n",
    "\n",
    "    # Probes\n",
    "    bm_p = nengo.Probe(bm, synapse=None)\n",
    "    an_in_p = nengo.Probe(an.input, synapse=None)\n",
    "    an_p = nengo.Probe(an.neuron_output, synapse=None)\n",
    "\n",
    "sim = nengo.Simulator(net, dt=dt)\n",
    "sim.run(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nengo.utils.matplotlib import rasterplot\n",
    "\n",
    "#sound = sim.data[audio_p]\n",
    "#plt.plot(sim.trange(), sound)\n",
    "#plt.xlim(right=sim.trange()[-1])\n",
    "plt.figure()\n",
    "cochleogram(sim.data[bm_p], sim.trange())\n",
    "plt.figure()\n",
    "cochleogram(sim.data[an_in_p], sim.trange())\n",
    "plt.figure()\n",
    "rasterplot(sim.trange(), sim.data[an_p])\n",
    "plt.ylim(0, cf.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
