{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech corpus\n",
    "\n",
    "[NLTK](http://www.nltk.org/) includes a small subset of the\n",
    "[TIMIT](https://catalog.ldc.upenn.edu/LDC93S1) corpus.\n",
    "Ideally, you want access to the full corpus, as we do.\n",
    "\n",
    "### Notes\n",
    "\n",
    "* [`nltk` corpus reader](https://github.com/nltk/nltk/blob/develop/nltk/corpus/reader/timit.py)\n",
    "* [`nltk` corpus reader example](https://github.com/nltk/nltk/blob/develop/nltk/test/corpus.doctest#L863)\n",
    "* Using TIMIT in PyLearn2\n",
    "  * https://ift6266h14.wordpress.com/experimenting/\n",
    "  * https://github.com/jfsantos/ift6266h14/blob/master/old/timit_full.py\n",
    "  * http://vdumoulin.github.io/articles/timit-part-2/\n",
    "  * https://jpraymond.wordpress.com/2014/02/21/using-the-new-an-improved-pylearn2-timit-dataset/\n",
    "  * https://github.com/vdumoulin/research/blob/master/code/pylearn2/datasets/timit.py\n",
    "  * https://github.com/jfsantos/ift6266h14/tree/master/old/pylearn2_timit\n",
    "\n",
    "### Possibly useful Python packages\n",
    "\n",
    "* [`PySoundFile`](https://github.com/bastibe/PySoundFile) (reads NIST Sphere, hopefully)\n",
    "* [`PySoundCard`](https://github.com/bastibe/PySoundCard)\n",
    "* [`audio` and related tools](https://github.com/boisgera?tab=repositories) (psychoacoustics?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    print(nltk.data.find('corpora/timit'))\n",
    "except:\n",
    "    nltk.download('timit')\n",
    "    print(nltk.data.find('corpora/timit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from nltk.corpus import timit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utt = timit.utteranceids()[0]\n",
    "Audio(data=timit.wav(utt, start=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incoporating with Nengo\n",
    "\n",
    "Basically, we want to use TIMIT\n",
    "to generate evaluation points\n",
    "and phoneme targets,\n",
    "which we will use to solve for\n",
    "appropriate decoding weights\n",
    "for the ensembles that represent\n",
    "acoustic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's work with a single utterance first\n",
    "import os\n",
    "\n",
    "# Get the utterance and the data associated with it\n",
    "region = 1\n",
    "sex = 'm'\n",
    "spkr_id = 'cpm0'\n",
    "sent_type = 'i'\n",
    "sent_number = 564\n",
    "\n",
    "timit_root = nltk.data.find('corpora/timit')\n",
    "spkr_dir = \"dr%d-%s%s\" % (region, sex, spkr_id)\n",
    "sent_file = \"s%s%d\" % (sent_type, sent_number)\n",
    "\n",
    "path = os.path.join(timit_root, spkr_dir, sent_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(filename=\"%s.wav\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import soundfile as sf\n",
    "\n",
    "data, fs = sf.read(\"%s.sph\" % path)  # Try the Sphere version\n",
    "dt = 1. / fs\n",
    "plt.plot(np.arange(data.size) * dt, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phone transcriptions are (fortunately!) available\n",
    "in `*.phn` files. Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat {path}.phn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonemes in TIMIT\n",
    "\n",
    "### Consonants\n",
    "\n",
    "#### Stops\n",
    "\n",
    "| Symbol | Example word    | Possible phonetic transcription |\n",
    "|--------|-----------------|---------------------------------|\n",
    "| b      |    bee          |    BCL B iy                     |\n",
    "| d      |    day          |    DCL D ey                     |\n",
    "| g      |    gay          |    GCL G ey                     |\n",
    "| p      |    pea          |    PCL P iy                     |\n",
    "| t      |    tea          |    TCL T iy                     |\n",
    "| k      |    key          |    KCL K iy                     |\n",
    "| dx     |    muddy, dirty |    m ah DX iy, dcl d er DX iy   |\n",
    "| q      |    bat          |    bcl b ae Q                   |\n",
    "\n",
    "####  Affricates\n",
    "\n",
    "| Symbol | Example word | Possible phonetic transcription |\n",
    "|--------|--------------|---------------------------------|\n",
    "| jh     |    joke      |    DCL JH ow kcl k              |\n",
    "| ch     |    choke     |    TCL CH ow kcl k              |\n",
    "\n",
    "####  Fricatives\n",
    "\n",
    "| Symbol | Example word | Possible phonetic transcription |\n",
    "|--------|--------------|---------------------------------|\n",
    "| s      |    sea       |    S iy                         |\n",
    "| sh     |    she       |    SH iy                        |\n",
    "| z      |    zone      |    Z ow n                       |\n",
    "| zh     |    azure     |    ae ZH er                     |\n",
    "| f      |    fin       |    F ih n                       |\n",
    "| th     |    thin      |    TH ih n                      |\n",
    "| v      |    van       |    V ae n                       |\n",
    "| dh     |    then      |    DH e n                       |\n",
    "\n",
    "#### Nasals\n",
    "\n",
    "| Symbol | Example word  | Possible phonetic transcription |\n",
    "|--------|---------------|---------------------------------|\n",
    "| m      |    mom        |    M aa M                       |\n",
    "| n      |    noon       |    N uw N                       |\n",
    "| ng     |    sing       |    s ih NG                      |\n",
    "| em     |    bottom     |    b aa tcl t EM                |\n",
    "| en     |    button     |    b ah q EN                    |\n",
    "| eng    |    washington |    w aa sh ENG tcl t ax n       |\n",
    "| nx     |    winner     |    w ih NX axr                  |\n",
    "\n",
    "#### Semivowels and glides\n",
    "\n",
    "| Symbol | Example word | Possible phonetic transcription |\n",
    "|--------|--------------|---------------------------------|\n",
    "| l      |    lay       |    L ey                         |\n",
    "| r      |    ray       |    R ey                         |\n",
    "| w      |    way       |    W ey                         |\n",
    "| y      |    yacht     |    Y aa tcl t                   |\n",
    "| hh     |    hay       |    HH ey                        |\n",
    "| hv     |    ahead     |    ax HV eh dcl d               |\n",
    "| el     |    bottle    |    bcl b aa tcl t EL            |\n",
    "\n",
    "###  Vowels\n",
    "\n",
    "| Symbol | Example word | Possible phonetic transcription  |\n",
    "|--------|--------------|----------------------------------|\n",
    "| iy     |    beet      |    bcl b IY tcl t                |\n",
    "| ih     |    bit       |    bcl b IH tcl t                |\n",
    "| eh     |    bet       |    bcl b EH tcl t                |\n",
    "| ey     |    bait      |    bcl b EY tcl t                |\n",
    "| ae     |    bat       |    bcl b AE tcl t                |\n",
    "| aa     |    bott      |    bcl b AA tcl t                |\n",
    "| aw     |    bout      |    bcl b AW tcl t                |\n",
    "| ay     |    bite      |    bcl b AY tcl t                |\n",
    "| ah     |    but       |    bcl b AH tcl t                |\n",
    "| ao     |    bought    |    bcl b AO tcl t                |\n",
    "| oy     |    boy       |    bcl b OY                      |\n",
    "| ow     |    boat      |    bcl b OW tcl t                |\n",
    "| uh     |    book      |    bcl b UH kcl k                |\n",
    "| uw     |    boot      |    bcl b UW tcl t                |\n",
    "| ux     |    toot      |    tcl t UX tcl t                |\n",
    "| er     |    bird      |    bcl b ER dcl d                |\n",
    "| ax     |    about     |    AX bcl b aw tcl t             |\n",
    "| ix     |    debit     |    dcl d eh bcl b IX tcl t       |\n",
    "| axr    |    butter    |    bcl b ah dx AXR               |\n",
    "| ax-h   |    suspect   |    s AX-H s pcl p eh kcl k tcl t |\n",
    "\n",
    "### Others\n",
    "\n",
    "| Symbol | Description                          |\n",
    "|--------|--------------------------------------|\n",
    "| pau    | pause                                |\n",
    "| epi    | epenthetic silence                   |\n",
    "| h#     | begin/end marker (non-speech events) |\n",
    "| 1      | primary stress marker                |\n",
    "| 2      | secondary stress marker              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consonants = [\n",
    "    'b', 'd', 'g', 'p', 't', 'k', 'dx', 'q',\n",
    "    'jh', 'ch',\n",
    "    's', 'sh', 'z', 'zh', 'f', 'th', 'v', 'dh',\n",
    "    'm', 'n', 'ng', 'em', 'en', 'eng', 'nx',\n",
    "    'l', 'r', 'w', 'y', 'hh', 'hv', 'el'\n",
    "]\n",
    "# \"the closure intervals of stops which are distinguished from the stop release\"\n",
    "closures = {\n",
    "    'bcl': 'b',\n",
    "    'dcl': 'd',\n",
    "    'gcl': 'g',\n",
    "    'pcl': 'p',\n",
    "    'tck': 't',\n",
    "    'kcl': 'k',\n",
    "    'dcl': 'jh',\n",
    "    'tcl': 'ch',\n",
    "}\n",
    "vowels = [\n",
    "    'iy', 'ih', 'eh', 'ey',\n",
    "    'ae', 'aa', 'aw', 'ay', 'ah', 'ao',\n",
    "    'oy', 'ow', 'uh', 'uw', 'ux',\n",
    "    'er', 'ax', 'ix', 'axr', 'ax-h',\n",
    "]\n",
    "ignores = [\n",
    "    'pau', 'epi', 'h#', '1', '2',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse a `.phn` file into a string of phonemes\n",
    "and their corresponding audio slices.\n",
    "We'll separate these into separate vowel\n",
    "and consonant lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cons = defaultdict(list)\n",
    "vows = defaultdict(list)\n",
    "\n",
    "with open(\"%s.phn\" % path, 'r') as phnfile:\n",
    "    for line in phnfile:\n",
    "        start, end, phn = line.split()\n",
    "        start, end = int(start), int(end)\n",
    "\n",
    "        if phn in ignores:\n",
    "            continue\n",
    "        if phn in closures:\n",
    "            phn = closures[phn]\n",
    "\n",
    "        dataslice = np.array(data[start:end])\n",
    "        if phn in consonants:\n",
    "            cons[phn].append(dataslice)\n",
    "        elif phn in vowels:\n",
    "            vows[phn].append(dataslice)\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized phoneme: '%s'\" % phn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look at all of the speech samples for a random vowel\n",
    "import random\n",
    "vow_phn = random.choice(list(vows))\n",
    "print(vow_phn)\n",
    "speech = np.concatenate(vows[vow_phn])\n",
    "plt.plot(speech)\n",
    "dt = 1. / fs\n",
    "plt.plot(np.arange(speech.size) * dt, speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's repeat this to get something we can listen to\n",
    "\n",
    "def timit_path(region, sex, spkr_id, sent_type, sent_number):\n",
    "    timit_root = nltk.data.find('corpora/timit')\n",
    "    spkr_dir = \"dr%d-%s%s\" % (region, sex, spkr_id)\n",
    "    sent_file = \"s%s%d\" % (sent_type, sent_number)\n",
    "    return os.path.join(timit_root, spkr_dir, sent_file)\n",
    "\n",
    "\n",
    "def add_utterance(tpath, cons, vows):\n",
    "    data, fs = sf.read(\"%s.sph\" % tpath)  # Try the Sphere version\n",
    "    with open(\"%s.phn\" % tpath, 'r') as phnfile:\n",
    "        for line in phnfile:\n",
    "            start, end, phn = line.split()\n",
    "            start, end = int(start), int(end)\n",
    "\n",
    "            if phn in ignores:\n",
    "                continue\n",
    "            if phn in closures:\n",
    "                phn = closures[phn]\n",
    "\n",
    "            dataslice = np.array(data[start:end])\n",
    "            if phn in consonants:\n",
    "                cons[phn].append(dataslice)\n",
    "            elif phn in vowels:\n",
    "                vows[phn].append(dataslice)\n",
    "            else:\n",
    "                raise ValueError(\"Unrecognized phoneme: '%s'\" % phn)\n",
    "\n",
    "cons = defaultdict(list)\n",
    "vows = defaultdict(list)\n",
    "\n",
    "region = 1\n",
    "sex = 'm'\n",
    "spkr_id = 'cpm0'\n",
    "\n",
    "for sent_type, sent_number in zip(['a', 'a', 'i', 'i', 'i', 'x',  'x', 'x', 'x'],\n",
    "                                  [1, 2, 564, 1194, 1824, 24, 114, 204, 294, 384]):\n",
    "    tpath = timit_path(region, sex, spkr_id, sent_type, sent_number)\n",
    "    add_utterance(tpath, cons=cons, vows=vows)\n",
    "\n",
    "# Let's hear all the 'ae' phonemes\n",
    "phn = np.concatenate(vows['ow']).ravel()\n",
    "print(phn.shape)\n",
    "Audio(data=phn, rate=fs)  # Dunno why this only works 10% of the time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from phd.sounds import ArrayProcess\n",
    "\n",
    "# Final step: transform cons and vows into eval_points and targets\n",
    "def phn2nengo(model, probe, phonemes, samples):\n",
    "    orig_sound = mode.auditory_filter.sound_process\n",
    "    dt = 1. / fs\n",
    "\n",
    "    eval_points = []\n",
    "    targets = []\n",
    "    for i, phoneme in enumerate(phonemes):\n",
    "        sound = np.concatenate(samples[phoneme]).ravel()\n",
    "        target = np.zeros((len(phonemes), sound.size))\n",
    "        target[i]\n",
    "        model.auditory_filter.sound_process = ArrayProcess(sound)\n",
    "        sim = nengo.Simulator(model, dt=dt*.5)\n",
    "        sim.run(dt * sound.size)\n",
    "        #if pool is not None:\n",
    "        #    d = vowel.shape[1] // pool\n",
    "        #    pooled_v = np.zeros((vowel.shape[0], d))\n",
    "        #    for p in range(d):\n",
    "        #        pooled_v[:, p] = np.sum(vowel[:, p*pool:(p+1)*pool], axis=1)\n",
    "        #    vowel = pooled_v\n",
    "        eval_points.append(sim.data[probe])\n",
    "        targets.append(target)\n",
    "\n",
    "    model.auditory_filter.sound_process = orig_sound\n",
    "    return np.concatenate(eval_points), np.concatenate(targets)\n",
    "\n",
    "# fs = 20000.\n",
    "freqs = phd.filters.erbspace(20, 10000, 64)\n",
    "sound = phd.sounds.WavFile('speech.wav')\n",
    "aud_filter = phd.filters.gammatone(freqs)\n",
    "cons_delay = 0.075\n",
    "vowel_delay = 0.03\n",
    "# Note: no integrator here\n",
    "\n",
    "model = phd.SpeechRecognition()\n",
    "model.add_periphery(freqs, sound, aud_filter, fs=fs, middle_ear=True)\n",
    "model.add_derivative(n_neurons=30, delay=cons_delay)\n",
    "model.add_derivative(n_neurons=30, delay=vowel_delay)\n",
    "\n",
    "with model:\n",
    "    # TODO: put all the info into one probe\n",
    "    pass\n",
    "\n",
    "with model:\n",
    "    vowel_p = nengo.Probe(vowel, synapse=0.01, sample_every=0.001)\n",
    "    cons_p = nengo.Probe(cons, synapse=0.01, sample_every=0.001)\n",
    "\n",
    "vowel_ep, vowel_targets = phn2nengo(model, v_probe, vowels, vows)\n",
    "cons_ep, cons_targets = phn2nengo(model, c_probe, consonants, cons)\n",
    "\n",
    "_, vow_detect = model.add_phoneme_detector(15, vowel_ep, vowel_targets, [vowel_delay])\n",
    "_, cons_detect = model.add_phoneme_detector(15, cons_ep, cons_targets, [cons_delay])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
