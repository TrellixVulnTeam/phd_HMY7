{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding words (phoneme strings)\n",
    "\n",
    "Let's use the SPA to encode words,\n",
    "or any arbitrary string of phonemes.\n",
    "Consider the word BAT.\n",
    "\n",
    "$$\\text{WORD} = \\text{PH1} \\circledast \\text{B} \\oplus \\text{PH2} \\circledast \\text{A} \\oplus \\text{PH3} \\circledast \\text{T} \\oplus \\text{PH4} \\circledast \\text{STOP}$$\n",
    "\n",
    "Then, we can decode the phone that we want\n",
    "by binding with the inverse of the\n",
    "phone that we're on.\n",
    "So, for the first phone:\n",
    "\n",
    "$$\\text{B} \\approx \\text{WORD} \\circledast \\text{PH1}^{-1}$$\n",
    "\n",
    "This result would then be sent to a cleanup memory.\n",
    "Unlike other cleanup memories, however,\n",
    "the outputs of the cleanup would be oscillators.\n",
    "These would generate the trajectory of articulators\n",
    "for each phoneme.\n",
    "\n",
    "As always, timing is the difficult thing here.\n",
    "Since these are oscillators, we really want to\n",
    "just give them a kick, so the cleanup shouldn't\n",
    "be cleaning up all the time, just when\n",
    "we query for the next phoneme.\n",
    "The kick should also advance the query\n",
    "to the next phone,\n",
    "so that the next kick gets the next phone.\n",
    "\n",
    "We'd need to build in some structure to the SPs\n",
    "representing phone positions.\n",
    "\n",
    "$$\\text{PH2} = \\text{PH1} \\circledast \\text{NEXTPH}$$\n",
    "\n",
    "And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nengo\n",
    "from nengo import spa\n",
    "from nengo.spa import Vocabulary\n",
    "import nengo_gui.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of dimensions for the Semantic Pointers\n",
    "dimensions = 128\n",
    "\n",
    "# Change the seed of this RNG to change the vocabulary\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# Assume a maximum of 8 phonemes. There are words with more,\n",
    "# but I would argue that you can make up those words from\n",
    "# smaller word parts chained together.\n",
    "# `PH2` to equal the convolution of `NEXTPH` with `PH1`, and so on.\n",
    "vocab = Vocabulary(dimensions=dimensions, rng=rng, unitary=['INC', 'PH1'])\n",
    "vocab.parse('INC')\n",
    "vocab.parse('PH1')\n",
    "for i in xrange(2, 9):\n",
    "    vocab.add('PH%d' % i, vocab.parse('PH%d * INC' % (i-1)))\n",
    "\n",
    "# English has 42 phonemes. That's nothing!\n",
    "# These are all the phonemes.\n",
    "#\n",
    "# /A/ /a/ /b/ /k/ /d/ /E/ /e/ /f/ /g/ /h/ /I/ /i/ /j/ /l/ /m/ /n/ /O/ /o/ /p/ /kw/ /r/ /s/ /t/\n",
    "# /U/ /u/ /v/ /w/ /ks/ /y/ /z/ /OO/ /oo/ /oi/ /ou/ /aw/ /ar/ /sh/ /hw/ /ch/ /th/ /ng/ /zh/\n",
    "#\n",
    "# Since SPs are all caps, we'll adopt the convention of doubling a letter for a capital;\n",
    "# e.g., /O/ becomes OO. We'll use underscores between letters to avoid ambiguities.\n",
    "#\n",
    "# TODO: build in something to do with vowels vs consonants?\n",
    "\n",
    "phs = ('AA', 'A', 'B', 'K', 'D', 'EE', 'E', 'F', 'G', 'H', 'II', 'I', 'J',\n",
    "       'L', 'M', 'N', 'OO', 'O', 'P', 'K_W', 'R', 'S', 'T',\n",
    "       'UU', 'U', 'V', 'W', 'K_S', 'Y', 'Z', 'OO_OO', 'O_O', 'O_I',\n",
    "       'O_U', 'A_W', 'A_R', 'S_H', 'H_W', 'C_H', 'T_H', 'N_G', 'Z_H')\n",
    "for ph in phs:\n",
    "    vocab.parse(ph)\n",
    "vocab.parse('STOP')  # special one to denote end of word\n",
    "\n",
    "just_phones = vocab.create_subset(phs + ('STOP',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_gain = 15\n",
    "neuron_per_d = 100\n",
    "\n",
    "with spa.SPA() as model:\n",
    "    model.word = spa.Buffer(dimensions=dimensions, neurons_per_dimension=100)\n",
    "\n",
    "    # ph_idx uses the two WM model from\n",
    "    # https://github.com/ctn-waterloo/summerschool2015/blob/master/tutorials/memory/Notebooks/4.UsingWM.ipynb\n",
    "    model.ph_idx1 = nengo.networks.InputGatedMemory(\n",
    "        neuron_per_d, dimensions=dimensions, difference_gain=difference_gain)\n",
    "    model.ph_idx2 = nengo.networks.InputGatedMemory(\n",
    "        neuron_per_d, dimensions=dimensions, difference_gain=difference_gain)\n",
    "    nengo.Connection(model.ph_idx1.output, model.ph_idx2.input) # Purple line\n",
    "    nengo.Connection(model.ph_idx2.output, model.ph_idx1.input,\n",
    "                     transform=vocab['INC'].get_convolution_matrix())\n",
    "\n",
    "    model.kick = nengo.Ensemble(100, dimensions=1,\n",
    "                                encoders=nengo.dists.Choice([[1]]),\n",
    "                                intercepts=nengo.dists.Uniform(0.2, 1))\n",
    "    nengo.Connection(model.kick, model.ph_idx1.gate)\n",
    "    # bias so that model.ph_idx2.gate gets 1 - kick\n",
    "    nengo.Connection(nengo.Node(1, label='kick bias'), model.ph_idx2.gate)\n",
    "    nengo.Connection(model.kick, model.ph_idx2.gate, transform=[-1])\n",
    "    \n",
    "    # phone = word * ~ph_idx\n",
    "    model.bind = nengo.networks.CircularConvolution(\n",
    "        neuron_per_d, dimensions, invert_a=False, invert_b=True)\n",
    "    nengo.Connection(model.word.state.output, model.bind.A)\n",
    "    nengo.Connection(model.ph_idx1.output, model.bind.B)\n",
    "    \n",
    "    # For quick testing\n",
    "    nengo.Connection(nengo.Node(lambda t: 1 if (t % 0.2) > 0.1 else 0, label='manual kick'), model.kick)\n",
    "    init_ph = nengo.Node(lambda t: vocab.parse('PH1').v if t < 0.2 else vocab.parse('0').v, label='init phone')\n",
    "    nengo.Connection(init_ph, model.ph_idx1.input)\n",
    "    nengo.Connection(nengo.Node(vocab.parse('PH1*B + PH2*A + PH3*D + PH4*STOP').v, label=\"word in\"),\n",
    "                     model.word.state.input)\n",
    "\n",
    "    kick_p = nengo.Probe(model.kick, synapse=0.01)\n",
    "    phidx_p = nengo.Probe(model.ph_idx1.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we use the associative memory simply\n",
    "to clean up to the correct semantic pointer.\n",
    "In this model, we'll leverage the fact that\n",
    "our clean up ensembles are already set up\n",
    "to have a dead zone that it needs to be\n",
    "kicked out of;\n",
    "we will change the clean up ensembles\n",
    "such that they essentially\n",
    "do what the oscillators in\n",
    "the 'synth choices' notebook do,\n",
    "with the exception of the `'STOP'`\n",
    "pointer, which will pass through as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    model.phone = spa.AssociativeMemory(just_phones)  # modify them here...\n",
    "    nengo.Connection(model.bind.output, model.phone.input)\n",
    "\n",
    "    phone_p = nengo.Probe(model.phone.output, synapse=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real engineering here is in how these clean up ensembles\n",
    "interact with the kick.\n",
    "The kick needs to start whenever\n",
    "we don't have an oscillator going.\n",
    "So, we have all of the oscillators\n",
    "inhibit the kick\n",
    "(it also uses modified intercepts,\n",
    "so a decoded connection inhibits).\n",
    "Since the `'STOP'` ensemble also inhibits the kick,\n",
    "we will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start an utterance, then,\n",
    "we just need to feed a word to `model.word`\n",
    "and `'PH1'` to `model.ph_idx1`.\n",
    "This should unbind to the right pointer,\n",
    "which will go through the cleanup and\n",
    "start that phoneme's oscillator.\n",
    "Once the oscillator is done (or nearly done),\n",
    "activity will cease,\n",
    "uninhibiting the kick ensemble.\n",
    "That causes the next phoneme index\n",
    "to be loaded up,\n",
    "which will unbind to a new pointer,\n",
    "starting that phoneme's oscillator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nengo_gui.ipython.IPythonViz(model, cfg='word.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(model)\n",
    "sim.run(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12));\n",
    "    \n",
    "plt.subplot(3, 1, 1);\n",
    "plt.plot(sim.trange(), \n",
    "         spa.similarity(sim.data[phidx_p],\n",
    "                        vocab.create_subset(['PH1', 'PH2', 'PH3', 'PH4'])))\n",
    "legend = plt.legend(['PH1', 'PH2', 'PH3', 'PH4', 'STOP'])\n",
    "legend.get_frame().set_facecolor('1')\n",
    "plt.ylim([-0.3, 1.1])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(sim.trange(), sim.data[kick_p])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(sim.trange(), \n",
    "         spa.similarity(sim.data[phone_p],\n",
    "                        vocab.create_subset(['B', 'A', 'D', 'STOP'])))\n",
    "legend = plt.legend(['B', 'A', 'D', 'STOP'])\n",
    "legend.get_frame().set_facecolor('1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
